import logging
import asyncio
import time
from datetime import datetime, timedelta, date
from typing import Dict, Any, List, Optional, Union
from config import Config, beijing_tz
import asyncpg
from asyncpg.pool import Pool

logger = logging.getLogger("GroupCheckInBot")


class PostgreSQLDatabase:
    """PostgreSQLæ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self, database_url: str = None):
        self.database_url = database_url or Config.DATABASE_URL
        self.pool: Optional[Pool] = None
        self._initialized = False
        self._cache = {}
        self._cache_ttl = {}

        # é‡è¿ç›¸å…³å±æ€§
        self._last_connection_check = 0
        self._connection_check_interval = 30
        self._reconnect_attempts = 0
        self._max_reconnect_attempts = 5
        self._reconnect_base_delay = 1.0

        self._maintenance_running = False
        self._maintenance_task = None
        self._connection_maintenance_task = None

        self._cache_max_size = 10000
        self._cache_access_order = []

    # ========== é‡è¿æœºåˆ¶ ==========
    async def _ensure_healthy_connection(self):
        """ç¡®ä¿è¿æ¥å¥åº·"""
        current_time = time.time()
        if current_time - self._last_connection_check < self._connection_check_interval:
            return True

        try:
            is_healthy = await self.connection_health_check()
            if not is_healthy:
                logger.warning("æ•°æ®åº“è¿æ¥ä¸å¥åº·ï¼Œå°è¯•é‡è¿...")
                await self._reconnect()

            self._last_connection_check = current_time
            return True
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
            return False

    async def _reconnect(self):
        """é‡æ–°å»ºç«‹æ•°æ®åº“è¿æ¥"""
        self._reconnect_attempts += 1

        if self._reconnect_attempts > self._max_reconnect_attempts:
            logger.error(
                f"æ•°æ®åº“é‡è¿å°è¯•æ¬¡æ•°è¶…è¿‡ä¸Šé™ ({self._max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿"
            )
            raise ConnectionError("æ•°æ®åº“é‡è¿å¤±è´¥")

        try:
            delay = self._reconnect_base_delay * (
                2 ** (self._reconnect_attempts - 1)
            )  # æŒ‡æ•°é€€é¿
            logger.info(f"{delay}ç§’åå°è¯•ç¬¬{self._reconnect_attempts}æ¬¡æ•°æ®åº“é‡è¿...")
            await asyncio.sleep(delay)

            # å…³é—­æ—§è¿æ¥
            if self.pool:
                await self.pool.close()

            # é‡æ–°åˆå§‹åŒ–
            self.pool = None
            self._initialized = False
            await self._initialize_impl()

            # é‡ç½®é‡è¿è®¡æ•°
            self._reconnect_attempts = 0
            logger.info("âœ… æ•°æ®åº“é‡è¿æˆåŠŸ")

        except Exception as e:
            logger.error(f"æ•°æ®åº“ç¬¬{self._reconnect_attempts}æ¬¡é‡è¿å¤±è´¥: {e}")
            if self._reconnect_attempts >= self._max_reconnect_attempts:
                logger.critical("æ•°æ®åº“é‡è¿æœ€ç»ˆå¤±è´¥ï¼ŒæœåŠ¡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
            raise

    async def execute_with_retry(
        self,
        operation_name: str,
        query: str,
        *args,
        fetch: bool = False,
        fetchrow: bool = False,
        fetchval: bool = False,  # ğŸ†• æ–°å¢ fetchval æ”¯æŒ
        max_retries: int = 2,
        timeout: int = 30,
        slow_threshold: float = 1.0,  # ğŸ†• å¯é…ç½®æ…¢æŸ¥è¯¢é˜ˆå€¼
    ):
        """å¸¦é‡è¯•å’Œè¶…æ—¶çš„æŸ¥è¯¢æ‰§è¡Œ - ç»ˆæä¼˜åŒ–ç‰ˆ"""
        if not await self._ensure_healthy_connection():
            raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

        # ğŸ†• éªŒè¯å‚æ•°ç»„åˆ
        if sum([fetch, fetchrow, fetchval]) > 1:
            raise ValueError("åªèƒ½æŒ‡å®šä¸€ç§æŸ¥è¯¢ç±»å‹: fetch, fetchrow æˆ– fetchval")

        for attempt in range(max_retries + 1):
            start_time = time.time()
            try:
                async with self.pool.acquire() as conn:
                    await conn.execute(f"SET statement_timeout = {timeout * 1000}")

                    if fetch:
                        result = await conn.fetch(query, *args)
                    elif fetchrow:
                        result = await conn.fetchrow(query, *args)
                    elif fetchval:
                        result = await conn.fetchval(query, *args)
                    else:
                        result = await conn.execute(query, *args)

                    execution_time = time.time() - start_time

                    # ğŸ†• åŠ¨æ€æ…¢æŸ¥è¯¢æ—¥å¿—
                    if execution_time > slow_threshold:
                        log_level = (
                            logging.WARNING if execution_time < 5.0 else logging.ERROR
                        )
                        logger.log(
                            log_level,
                            f"â±ï¸ æ…¢æŸ¥è¯¢: {operation_name} è€—æ—¶ {execution_time:.3f}ç§’ "
                            f"(SQL: {query[:100]}{'...' if len(query) > 100 else ''})",
                        )

                    return result

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                retry_delay = min(1 * (2**attempt), 5)
                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œ{retry_delay}ç§’åç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(retry_delay)

            except asyncpg.QueryCanceledError:
                logger.error(f"{operation_name} æŸ¥è¯¢è¶…æ—¶è¢«å–æ¶ˆ (è¶…æ—¶è®¾ç½®: {timeout}ç§’)")
                if attempt == max_retries:
                    raise
                await asyncio.sleep(1)

            except Exception as e:
                # ğŸ†• åŒºåˆ†æ•°æ®åº“é”™è¯¯å’Œå…¶ä»–é”™è¯¯
                if "database" in str(e).lower() or "sql" in str(e).lower():
                    logger.error(f"{operation_name} æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
                else:
                    logger.error(f"{operation_name} æ“ä½œå¤±è´¥: {e}")
                raise

    async def fetch_with_retry(
        self, operation_name: str, query: str, *args, max_retries: int = 2
    ):
        """å¸¦é‡è¯•çš„æŸ¥è¯¢è·å–"""
        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿è¿æ¥å¥åº·
                if not await self._ensure_healthy_connection():
                    raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                async with self.pool.acquire() as conn:
                    return await conn.fetch(query, *args)

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"{operation_name} æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                raise

    async def fetchrow_with_retry(
        self, operation_name: str, query: str, *args, max_retries: int = 2
    ):
        """å¸¦é‡è¯•çš„å•è¡ŒæŸ¥è¯¢"""
        for attempt in range(max_retries + 1):
            try:
                # ç¡®ä¿è¿æ¥å¥åº·
                if not await self._ensure_healthy_connection():
                    raise ConnectionError("æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                async with self.pool.acquire() as conn:
                    return await conn.fetchrow(query, *args)

            except (
                asyncpg.PostgresConnectionError,
                asyncpg.ConnectionDoesNotExistError,
                asyncpg.InterfaceError,
                ConnectionError,
            ) as e:
                if attempt == max_retries:
                    logger.error(
                        f"{operation_name} æ•°æ®åº“é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}"
                    )
                    raise

                logger.warning(
                    f"{operation_name} æ•°æ®åº“è¿æ¥å¼‚å¸¸ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}"
                )
                await self._reconnect()
                await asyncio.sleep(1)

            except Exception as e:
                logger.error(f"{operation_name} æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
                raise

    # ========== å®šæœŸç»´æŠ¤ä»»åŠ¡ ==========
    async def start_connection_maintenance(self):
        """å¯åŠ¨è¿æ¥ç»´æŠ¤ä»»åŠ¡"""
        if hasattr(self, "_maintenance_running") and self._maintenance_running:
            logger.info("è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²åœ¨è¿è¡Œ")
            return

        self._maintenance_running = True
        self._maintenance_task = asyncio.create_task(
            self._connection_maintenance_loop()
        )
        logger.info("âœ… æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²å¯åŠ¨")

    async def stop_connection_maintenance(self):
        """åœæ­¢è¿æ¥ç»´æŠ¤ä»»åŠ¡"""
        self._maintenance_running = False
        if hasattr(self, "_maintenance_task") and self._maintenance_task:
            self._maintenance_task.cancel()
            try:
                await self._maintenance_task
            except asyncio.CancelledError:
                pass
            self._maintenance_task = None
        logger.info("æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡å·²åœæ­¢")

    async def _connection_maintenance_loop(self):
        """è¿æ¥ç»´æŠ¤å¾ªç¯"""
        logger.info("å¼€å§‹æ•°æ®åº“è¿æ¥ç»´æŠ¤å¾ªç¯...")

        while self._maintenance_running:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

                # æ‰§è¡Œè¿æ¥å¥åº·æ£€æŸ¥
                if not await self._ensure_healthy_connection():
                    logger.warning("è¿æ¥ç»´æŠ¤: æ•°æ®åº“è¿æ¥ä¸å¥åº·")

                # æ¸…ç†è¿‡æœŸç¼“å­˜
                await self.cleanup_cache()

                # å®šæœŸæ¸…ç†æœˆåº¦æ•°æ®ï¼ˆå¯é€‰ï¼‰
                current_time = time.time()
                if current_time % 3600 < 60:  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
                    try:
                        await self.cleanup_old_data(days=Config.DATA_RETENTION_DAYS)
                        logger.debug("å®šæœŸæ•°æ®æ¸…ç†å®Œæˆ")
                    except Exception as e:
                        logger.error(f"å®šæœŸæ•°æ®æ¸…ç†å¤±è´¥: {e}")

            except asyncio.CancelledError:
                logger.info("æ•°æ®åº“è¿æ¥ç»´æŠ¤ä»»åŠ¡è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"è¿æ¥ç»´æŠ¤ä»»åŠ¡å¼‚å¸¸: {e}")
                await asyncio.sleep(30)  # å¼‚å¸¸åç­‰å¾…30ç§’å†ç»§ç»­

    # ========== æ—¶åŒºç›¸å…³æ–¹æ³• ==========
    def get_beijing_time(self):
        """è·å–åŒ—äº¬æ—¶é—´"""
        return datetime.now(beijing_tz)

    def get_beijing_date(self):
        """è·å–åŒ—äº¬æ—¥æœŸ"""
        return self.get_beijing_time().date()

    # ========= ç»Ÿä¸€æ—¶é—´ =========
    async def get_reset_period_date(
        self, chat_id: int, target_datetime: datetime = None
    ) -> date:
        """æ ¹æ®ç¾¤ç»„é‡ç½®æ—¶é—´è·å–é‡ç½®å‘¨æœŸæ—¥æœŸ"""
        if target_datetime is None:
            target_datetime = self.get_beijing_time()

        try:
            group_data = await self.get_group_cached(chat_id)
            if not group_data:
                await self.init_group(chat_id)
                group_data = await self.get_group_cached(chat_id)

            reset_hour = group_data.get("reset_hour", Config.DAILY_RESET_HOUR)
            reset_minute = group_data.get("reset_minute", Config.DAILY_RESET_MINUTE)

            # è®¡ç®—ä»Šå¤©çš„é‡ç½®æ—¶é—´ç‚¹
            reset_time_today = target_datetime.replace(
                hour=reset_hour, minute=reset_minute, second=0, microsecond=0
            )

            # åˆ¤æ–­å½“å‰æ—¶é—´ä¸é‡ç½®æ—¶é—´çš„å…³ç³»
            if target_datetime < reset_time_today:
                # å½“å‰æ—¶é—´åœ¨ä»Šå¤©é‡ç½®æ—¶é—´ä¹‹å‰ï¼Œå±äºæ˜¨å¤©çš„å‘¨æœŸ
                return (reset_time_today - timedelta(days=1)).date()
            else:
                # å½“å‰æ—¶é—´åœ¨ä»Šå¤©é‡ç½®æ—¶é—´ä¹‹åï¼Œå±äºä»Šå¤©çš„å‘¨æœŸ
                return reset_time_today.date()

        except Exception as e:
            logger.error(f"è®¡ç®—é‡ç½®å‘¨æœŸæ—¥æœŸå¤±è´¥ {chat_id}: {e}")
            # å‡ºé”™æ—¶è¿”å›è‡ªç„¶æ—¥
            return target_datetime.date()

    async def has_reset_executed_today(
        self, chat_id: int, target_datetime: datetime = None
    ) -> tuple[bool, str]:
        """
        è¿”å›ï¼š(æ˜¯å¦æ‰§è¡Œè¿‡, åŸå› )
        """
        if target_datetime is None:
            target_datetime = self.get_beijing_time()

        today = target_datetime.date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            # è·å–å½“å‰é…ç½®å’Œæœ€åè®°å½•
            row = await conn.fetchrow(
                """
                SELECT 
                    g.reset_hour,
                    g.reset_minute,
                    g.last_reset_date,
                    g.last_reset_config
                FROM groups g
                WHERE g.chat_id = $1
                """,
                chat_id,
            )

            if not row or not row["last_reset_date"]:
                return False, "ä»æœªé‡ç½®è¿‡"

            last_date = row["last_reset_date"]
            last_config = row["last_reset_config"] or ""
            current_config = f"{row['reset_hour']}:{row['reset_minute']}"

            if last_date != today:
                return False, "ä»Šå¤©æœªé‡ç½®è¿‡"

            if last_config != current_config:
                return False, "é‡ç½®é…ç½®å·²å˜æ›´"

            return True, "ä»Šå¤©å·²æŒ‰ç›¸åŒé…ç½®é‡ç½®è¿‡"

    async def get_last_reset_info(self, chat_id: int) -> Optional[Dict]:
        """è·å–ç¾¤ç»„æœ€åä¸€æ¬¡é‡ç½®çš„ä¿¡æ¯"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                """
                SELECT last_reset_date, last_reset_config 
                FROM groups 
                WHERE chat_id = $1
                """,
                chat_id,
            )
            if not row or not row["last_reset_date"]:
                return None

            info = {
                "reset_date": row["last_reset_date"],
                "reset_config": row["last_reset_config"],
            }

            # è§£æé…ç½®å­—ç¬¦ä¸²
            if row["last_reset_config"]:
                try:
                    hour_str, minute_str = row["last_reset_config"].split(":")
                    info["reset_hour"] = int(hour_str)
                    info["reset_minute"] = int(minute_str)
                except:
                    pass

            return info

    async def mark_reset_executed(
        self,
        chat_id: int,
        reset_hour: int,
        reset_minute: int,
        execution_time: datetime = None,
    ):
        """æ ‡è®°é‡ç½®å·²æ‰§è¡Œ"""
        if execution_time is None:
            execution_time = self.get_beijing_time()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                UPDATE groups SET 
                    last_reset_date = $1,
                    last_reset_config = $2,
                    updated_at = CURRENT_TIMESTAMP
                WHERE chat_id = $3
                """,
                execution_time.date(),
                f"{reset_hour}:{reset_minute}",
                chat_id,
            )
            logger.debug(
                f"é‡ç½®æ ‡è®°å·²ä¿å­˜: ç¾¤ç»„{chat_id}, æ—¥æœŸ{execution_time.date()}, é…ç½®{reset_hour}:{reset_minute}"
            )

    async def clear_today_reset_record(self, chat_id: int):
        """æ¸…é™¤ä»Šå¤©çš„é‡ç½®è®°å½•ï¼ˆç”¨äºé‡ç½®æ—¶é—´å˜æ›´æ—¶ï¼‰"""
        today = self.get_beijing_time().date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                UPDATE groups SET 
                    last_reset_date = NULL,
                    last_reset_config = NULL
                WHERE chat_id = $1 AND last_reset_date = $2
                """,
                chat_id,
                today,
            )
            logger.info(f"æ¸…é™¤ä»Šå¤©é‡ç½®è®°å½•: ç¾¤ç»„{chat_id}")

    async def has_work_record_in_period(
        self, chat_id: int, user_id: int, checkin_type: str, target_datetime: datetime
    ) -> bool:
        """æ£€æŸ¥å½“å‰é‡ç½®å‘¨æœŸå†…æ˜¯å¦æœ‰ä¸Šä¸‹ç­è®°å½•"""
        try:
            period_date = await self.get_reset_period_date(chat_id, target_datetime)

            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow(
                    """
                    SELECT 1 FROM work_records 
                    WHERE chat_id = $1 AND user_id = $2 
                    AND checkin_type = $3 AND record_date = $4
                    """,
                    chat_id,
                    user_id,
                    checkin_type,
                    period_date,
                )
                return row is not None
        except Exception as e:
            logger.error(f"æ£€æŸ¥å·¥ä½œè®°å½•å¤±è´¥ {chat_id}-{user_id}: {e}")
            return False

    async def get_work_records_in_period(
        self, chat_id: int, user_id: int, period_date: date
    ) -> Dict[str, Dict]:
        """è·å–å½“å‰é‡ç½®å‘¨æœŸçš„ä¸Šä¸‹ç­è®°å½•"""
        try:
            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                rows = await conn.fetch(
                    """
                    SELECT * FROM work_records 
                    WHERE chat_id = $1 AND user_id = $2 AND record_date = $3
                    ORDER BY checkin_type
                    """,
                    chat_id,
                    user_id,
                    period_date,
                )

                records = {}
                for row in rows:
                    records[row["checkin_type"]] = dict(row)
                return records
        except Exception as e:
            logger.error(f"è·å–å·¥ä½œè®°å½•å¤±è´¥ {chat_id}-{user_id}: {e}")
            return {}

    # ========== åˆå§‹åŒ–æ–¹æ³• ==========
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if self._initialized:
            return

        max_retries = 5
        for attempt in range(max_retries):
            try:
                logger.info(f"è¿æ¥PostgreSQLæ•°æ®åº“ (å°è¯• {attempt + 1}/{max_retries})")
                await self._initialize_impl()
                logger.info("PostgreSQLæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
                self._initialized = True
                return
            except Exception as e:
                logger.warning(f"æ•°æ®åº“åˆå§‹åŒ–ç¬¬ {attempt + 1} æ¬¡å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    logger.error(f"æ•°æ®åº“åˆå§‹åŒ–é‡è¯•{max_retries}æ¬¡åå¤±è´¥: {e}")
                    # å°è¯•å¼ºåˆ¶é‡å»ºè¡¨
                    try:
                        await self._force_recreate_tables()
                        self._initialized = True
                        logger.info("âœ… æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºæˆåŠŸ")
                        return
                    except Exception as rebuild_error:
                        logger.error(f"æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºå¤±è´¥: {rebuild_error}")
                        raise e
                await asyncio.sleep(2**attempt)

    async def _initialize_impl(self):
        """å®é™…çš„æ•°æ®åº“åˆå§‹åŒ–å®ç°"""
        self.pool = await asyncpg.create_pool(
            self.database_url,
            min_size=Config.DB_MIN_CONNECTIONS,
            max_size=Config.DB_MAX_CONNECTIONS,
            max_inactive_connection_lifetime=Config.DB_POOL_RECYCLE,
            command_timeout=Config.DB_CONNECTION_TIMEOUT,
            timeout=60,
        )
        logger.info("PostgreSQLè¿æ¥æ± åˆ›å»ºæˆåŠŸ")

        async with self.pool.acquire() as conn:
            await conn.execute("SET statement_timeout = 30000")
            await conn.execute("SET idle_in_transaction_session_timeout = 60000")

        # åˆ›å»ºè¡¨å’Œç´¢å¼• - æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                await self._create_tables()
                await self._create_indexes()
                await self._initialize_default_data()
                logger.info("âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–å®Œæˆ")
                break
            except Exception as e:
                logger.warning(f"æ•°æ®åº“è¡¨åˆå§‹åŒ–ç¬¬ {attempt + 1} æ¬¡å¤±è´¥: {e}")
                if attempt == max_retries - 1:
                    logger.error("æ•°æ®åº“è¡¨åˆå§‹åŒ–æœ€ç»ˆå¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶é‡å»º...")
                    await self._force_recreate_tables()
                await asyncio.sleep(1)

    async def _force_recreate_tables(self):
        """å¼ºåˆ¶é‡æ–°åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆç”¨äºä¿®å¤æŸåçš„æ•°æ®åº“ï¼‰"""
        logger.warning("ğŸ”„ å¼ºåˆ¶é‡æ–°åˆ›å»ºæ•°æ®åº“è¡¨...")

        async with self.pool.acquire() as conn:
            # åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆæŒ‰ä¾èµ–é¡ºåºï¼‰
            tables = [
                "monthly_statistics",
                "activity_user_limits",
                "push_settings",
                "work_fine_configs",
                "fine_configs",
                "activity_configs",
                "work_records",
                "user_activities",
                "users",
                "groups",
            ]

            for table in tables:
                try:
                    await conn.execute(f"DROP TABLE IF EXISTS {table} CASCADE")
                    logger.info(f"âœ… åˆ é™¤è¡¨: {table}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤è¡¨ {table} å¤±è´¥: {e}")

            # é‡æ–°åˆ›å»ºè¡¨
            await self._create_tables()
            await self._create_indexes()
            await self._initialize_default_data()
            logger.info("ğŸ‰ æ•°æ®åº“è¡¨å¼ºåˆ¶é‡å»ºå®Œæˆ")

    def _extract_table_name(self, table_sql: str) -> str:
        """å®‰å…¨æå–è¡¨å"""
        try:
            # ä½¿ç”¨æ›´ç¨³å®šçš„æ–¹å¼æå–è¡¨å
            words = table_sql.upper().split()
            if "TABLE" in words:
                table_index = words.index("TABLE") + 1
                if table_index < len(words) and words[table_index] == "IF":
                    table_index += 3  # è·³è¿‡ IF NOT EXISTS
                elif table_index < len(words) and words[table_index] == "NOT":
                    table_index += 2  # è·³è¿‡ NOT EXISTS
                return words[table_index] if table_index < len(words) else "unknown"
        except Exception:
            pass
        return "unknown"

    async def _create_tables(self):
        """åˆ›å»ºæ‰€æœ‰å¿…è¦çš„è¡¨"""
        async with self.pool.acquire() as conn:
            tables = [
                # groupsè¡¨
                """
                CREATE TABLE IF NOT EXISTS groups (
                    chat_id BIGINT PRIMARY KEY,
                    channel_id BIGINT,
                    notification_group_id BIGINT,
                    reset_hour INTEGER DEFAULT 0,
                    reset_minute INTEGER DEFAULT 0,
                    work_start_time TEXT DEFAULT '09:00',
                    work_end_time TEXT DEFAULT '18:00',
                    last_reset_date DATE,
                    last_reset_config TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # usersè¡¨
                """
                CREATE TABLE IF NOT EXISTS users (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT NOT NULL,
                    user_id BIGINT NOT NULL,
                    nickname TEXT,
                    current_activity TEXT,
                    activity_start_time TEXT,
                    total_accumulated_time INTEGER DEFAULT 0,
                    total_activity_count INTEGER DEFAULT 0,
                    total_fines INTEGER DEFAULT 0,
                    overtime_count INTEGER DEFAULT 0,
                    total_overtime_time INTEGER DEFAULT 0,
                    last_updated DATE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id)
                )
                """,
                # user_activitiesè¡¨
                """
                CREATE TABLE IF NOT EXISTS user_activities (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    activity_date DATE,
                    activity_name TEXT,
                    activity_count INTEGER DEFAULT 0,
                    accumulated_time INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, activity_date, activity_name)
                )
                """,
                # work_recordsè¡¨
                """
                CREATE TABLE IF NOT EXISTS work_records (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    record_date DATE,
                    checkin_type TEXT,
                    checkin_time TEXT,
                    status TEXT,
                    time_diff_minutes REAL,
                    fine_amount INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, record_date, checkin_type)
                )
                """,
                # activity_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS activity_configs (
                    activity_name TEXT PRIMARY KEY,
                    max_times INTEGER,
                    time_limit INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # fine_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS fine_configs (
                    id SERIAL PRIMARY KEY,
                    activity_name TEXT,
                    time_segment TEXT,
                    fine_amount INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(activity_name, time_segment)
                )
                """,
                # work_fine_configsè¡¨
                """
                CREATE TABLE IF NOT EXISTS work_fine_configs (
                    id SERIAL PRIMARY KEY,
                    checkin_type TEXT,
                    time_segment TEXT,
                    fine_amount INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(checkin_type, time_segment)
                )
                """,
                # push_settingsè¡¨
                """
                CREATE TABLE IF NOT EXISTS push_settings (
                    setting_key TEXT PRIMARY KEY,
                    setting_value INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
                # monthly_statisticsè¡¨
                """
                CREATE TABLE IF NOT EXISTS monthly_statistics (
                    id SERIAL PRIMARY KEY,
                    chat_id BIGINT,
                    user_id BIGINT,
                    statistic_date DATE,
                    activity_name TEXT,
                    activity_count INTEGER DEFAULT 0,
                    accumulated_time INTEGER DEFAULT 0,
                    work_days INTEGER DEFAULT 0,
                    work_hours INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(chat_id, user_id, statistic_date, activity_name)
                )
                """,
                # activity_user_limitsè¡¨
                """
                CREATE TABLE IF NOT EXISTS activity_user_limits (
                    activity_name TEXT PRIMARY KEY,
                    max_users INTEGER DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """,
            ]

            for table_sql in tables:
                try:
                    await conn.execute(table_sql)
                    table_name = self._extract_table_name(table_sql)
                    logger.info(f"âœ… åˆ›å»ºè¡¨: {table_name}")
                except Exception as e:
                    logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
                    # è®°å½•å¤±è´¥çš„SQLç”¨äºè°ƒè¯•
                    logger.error(f"å¤±è´¥çš„SQL: {table_sql[:100]}...")
                    raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸è®©ä¸Šå±‚å¤„ç†
            logger.info("æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")

    async def _create_indexes(self):
        """åˆ›å»ºæ€§èƒ½ç´¢å¼•"""
        async with self.pool.acquire() as conn:
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_user_activities_main ON user_activities (chat_id, user_id, activity_date)",
                "CREATE INDEX IF NOT EXISTS idx_work_records_main ON work_records (chat_id, user_id, record_date)",
                "CREATE INDEX IF NOT EXISTS idx_users_main ON users (chat_id, user_id)",
                "CREATE INDEX IF NOT EXISTS idx_monthly_stats_main ON monthly_statistics (chat_id, user_id, statistic_date)",
            ]

            for index_sql in indexes:
                try:
                    await conn.execute(index_sql)
                    index_name = index_sql.split()[5]  # è·å–ç´¢å¼•å
                    logger.info(f"âœ… åˆ›å»ºç´¢å¼•: {index_name}")
                except Exception as e:
                    logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
                    # ç´¢å¼•åˆ›å»ºå¤±è´¥ä¸é˜»æ­¢ç¨‹åºå¯åŠ¨
            logger.info("æ•°æ®åº“ç´¢å¼•åˆ›å»ºå®Œæˆ")

    async def _initialize_default_data(self):
        """åˆå§‹åŒ–é»˜è®¤æ•°æ®"""
        async with self.pool.acquire() as conn:
            # åˆå§‹åŒ–æ´»åŠ¨é…ç½®
            for activity, limits in Config.DEFAULT_ACTIVITY_LIMITS.items():
                await conn.execute(
                    "INSERT INTO activity_configs (activity_name, max_times, time_limit) VALUES ($1, $2, $3) ON CONFLICT (activity_name) DO NOTHING",
                    activity,
                    limits["max_times"],
                    limits["time_limit"],
                )
                logger.info(f"âœ… åˆå§‹åŒ–æ´»åŠ¨é…ç½®: {activity}")

            # åˆå§‹åŒ–ç½šæ¬¾é…ç½®
            for activity, fines in Config.DEFAULT_FINE_RATES.items():
                for time_segment, amount in fines.items():
                    await conn.execute(
                        "INSERT INTO fine_configs (activity_name, time_segment, fine_amount) VALUES ($1, $2, $3) ON CONFLICT (activity_name, time_segment) DO NOTHING",
                        activity,
                        time_segment,
                        amount,
                    )
                logger.info(f"âœ… åˆå§‹åŒ–ç½šæ¬¾é…ç½®: {activity}")

            # åˆå§‹åŒ–æ¨é€è®¾ç½®
            for key, value in Config.AUTO_EXPORT_SETTINGS.items():
                await conn.execute(
                    "INSERT INTO push_settings (setting_key, setting_value) VALUES ($1, $2) ON CONFLICT (setting_key) DO NOTHING",
                    key,
                    1 if value else 0,
                )
                logger.info(f"âœ… åˆå§‹åŒ–æ¨é€è®¾ç½®: {key}")

            logger.info("é»˜è®¤æ•°æ®åˆå§‹åŒ–å®Œæˆ")

    async def health_check(self) -> bool:
        """å®Œæ•´çš„æ•°æ®åº“å¥åº·æ£€æŸ¥ - å¢å¼ºç‰ˆ"""
        if not self.pool or not self._initialized:
            logger.warning("æ•°æ®åº“æœªåˆå§‹åŒ–")
            return False

        try:
            async with self.pool.acquire() as conn:
                # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                result = await conn.fetchval("SELECT 1")
                if result != 1:
                    return False

                # æ£€æŸ¥å…³é”®è¡¨æ˜¯å¦å­˜åœ¨ä¸”å¯è®¿é—®
                critical_tables = ["users", "groups", "activity_configs"]
                for table in critical_tables:
                    try:
                        await conn.fetchval(f"SELECT 1 FROM {table} LIMIT 1")
                    except Exception as e:
                        logger.error(f"âŒ å…³é”®è¡¨ {table} è®¿é—®å¤±è´¥: {e}")
                        return False

                return True
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    # ========== è¿æ¥ç®¡ç† ==========
    def _ensure_pool_initialized(self):
        """ç¡®ä¿è¿æ¥æ± å·²åˆå§‹åŒ–"""
        if not self.pool or not self._initialized:
            raise RuntimeError("æ•°æ®åº“è¿æ¥æ± å°šæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize() æ–¹æ³•")

    async def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        self._ensure_pool_initialized()
        return await self.pool.acquire()

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        try:
            if self.pool:
                await self.pool.close()
                logger.info("PostgreSQLè¿æ¥æ± å·²å…³é—­")
        except Exception as e:
            logger.warning(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºç°å¼‚å¸¸: {e}")

    # ========== ç¼“å­˜ç®¡ç† ==========
    def _get_cached(self, key: str):
        """è·å–ç¼“å­˜æ•°æ®"""
        if key in self._cache_ttl and time.time() < self._cache_ttl[key]:
            return self._cache.get(key)
        else:
            # æ¸…ç†è¿‡æœŸç¼“å­˜
            if key in self._cache:
                del self._cache[key]
            if key in self._cache_ttl:
                del self._cache_ttl[key]
            return None

    def _set_cached(self, key: str, value: Any, ttl: int = 60):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        self._cache[key] = value
        self._cache_ttl[key] = time.time() + ttl

    async def cleanup_cache(self):
        """ğŸ†• å¢å¼ºçš„ç¼“å­˜æ¸…ç† - è¿‡æœŸæ¸…ç† + LRUæ¸…ç†"""
        current_time = time.time()
        expired_keys = [
            key for key, expiry in self._cache_ttl.items() if current_time >= expiry
        ]

        for key in expired_keys:
            self._cache.pop(key, None)
            self._cache_ttl.pop(key, None)
            if key in self._cache_access_order:
                self._cache_access_order.remove(key)

        # ğŸ†• é¢å¤–æ¸…ç†ï¼šå¦‚æœç¼“å­˜ä»ç„¶è¿‡å¤§ï¼Œç§»é™¤æœ€æ—§çš„ä¸€äº›æ¡ç›®
        if len(self._cache) > self._cache_max_size * 0.8:  # 80%é˜ˆå€¼
            excess = len(self._cache) - int(self._cache_max_size * 0.7)  # æ¸…ç†åˆ°70%
            if excess > 0 and self._cache_access_order:
                keys_to_remove = self._cache_access_order[:excess]
                for key in keys_to_remove:
                    self._cache.pop(key, None)
                    self._cache_ttl.pop(key, None)
                self._cache_access_order = self._cache_access_order[excess:]
                logger.info(f"LRUå¼ºåˆ¶æ¸…ç†: ç§»é™¤äº† {len(keys_to_remove)} ä¸ªæ—§ç¼“å­˜")

        if expired_keys:
            logger.debug(
                f"ç¼“å­˜æ¸…ç†å®Œæˆ: {len(expired_keys)}ä¸ªè¿‡æœŸ, å½“å‰å¤§å°: {len(self._cache)}"
            )

    async def force_refresh_activity_cache(self):
        """å¼ºåˆ¶åˆ·æ–°æ´»åŠ¨é…ç½®ç¼“å­˜"""
        cache_keys_to_remove = ["activity_limits", "push_settings", "fine_rates"]
        for key in cache_keys_to_remove:
            self._cache.pop(key, None)
            self._cache_ttl.pop(key, None)
        await self.get_activity_limits()
        await self.get_fine_rates()
        logger.info("æ´»åŠ¨é…ç½®ç¼“å­˜å·²å¼ºåˆ¶åˆ·æ–°")

    # ========== ç¾¤ç»„ç›¸å…³æ“ä½œ ==========
    async def init_group(self, chat_id: int):
        """åˆå§‹åŒ–ç¾¤ç»„ - å¸¦é‡è¯•"""
        await self.execute_with_retry(
            "åˆå§‹åŒ–ç¾¤ç»„",
            "INSERT INTO groups (chat_id) VALUES ($1) ON CONFLICT (chat_id) DO NOTHING",
            chat_id,
        )
        self._cache.pop(f"group:{chat_id}", None)

    async def get_group(self, chat_id: int) -> Optional[Dict]:
        """è·å–ç¾¤ç»„é…ç½®"""
        cache_key = f"group:{chat_id}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT * FROM groups WHERE chat_id = $1", chat_id
            )
            if row:
                result = dict(row)
                self._set_cached(cache_key, result, 300)
                return result
            return None

    async def get_group_cached(self, chat_id: int) -> Optional[Dict]:
        """å¸¦ç¼“å­˜çš„è·å–ç¾¤ç»„é…ç½®"""
        return await self.get_group(chat_id)

    async def update_group_channel(self, chat_id: int, channel_id: int):
        """æ›´æ–°ç¾¤ç»„é¢‘é“ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET channel_id = $1, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $2",
                channel_id,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def update_group_notification(self, chat_id: int, group_id: int):
        """æ›´æ–°ç¾¤ç»„é€šçŸ¥ç¾¤ç»„ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET notification_group_id = $1, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $2",
                group_id,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def update_group_reset_time(self, chat_id: int, hour: int, minute: int):
        """æ›´æ–°ç¾¤ç»„é‡ç½®æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                UPDATE groups SET 
                    reset_hour = $1, 
                    reset_minute = $2, 
                    updated_at = CURRENT_TIMESTAMP
                WHERE chat_id = $3
                """,
                hour,
                minute,
                chat_id,
            )

            # ğŸ¯ å…³é”®ï¼šæ¸…é™¤ä»Šå¤©çš„é‡ç½®è®°å½•ï¼Œç¡®ä¿æ–°æ—¶é—´èƒ½ç”Ÿæ•ˆ
            await self.clear_today_reset_record(chat_id)

            # ğŸ§¹ æ¸…ç†ç¼“å­˜
            self._cache.pop(f"group:{chat_id}", None)

            logger.info(f"é‡ç½®æ—¶é—´æ›´æ–°: ç¾¤ç»„{chat_id} -> {hour:02d}:{minute:02d}")

    async def update_group_work_time(
        self, chat_id: int, work_start: str, work_end: str
    ):
        """æ›´æ–°ç¾¤ç»„ä¸Šä¸‹ç­æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE groups SET work_start_time = $1, work_end_time = $2, updated_at = CURRENT_TIMESTAMP WHERE chat_id = $3",
                work_start,
                work_end,
                chat_id,
            )
            self._cache.pop(f"group:{chat_id}", None)

    async def get_group_work_time(self, chat_id: int) -> Dict[str, str]:
        """è·å–ç¾¤ç»„ä¸Šä¸‹ç­æ—¶é—´ - å¸¦é‡è¯•"""
        row = await self.fetchrow_with_retry(
            "è·å–å·¥ä½œæ—¶é—´",
            "SELECT work_start_time, work_end_time FROM groups WHERE chat_id = $1",
            chat_id,
        )
        if row and row["work_start_time"] and row["work_end_time"]:
            return {
                "work_start": row["work_start_time"],
                "work_end": row["work_end_time"],
            }
        return Config.DEFAULT_WORK_HOURS.copy()

    async def has_work_hours_enabled(self, chat_id: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†ä¸Šä¸‹ç­åŠŸèƒ½"""
        work_hours = await self.get_group_work_time(chat_id)
        return (
            work_hours["work_start"] != Config.DEFAULT_WORK_HOURS["work_start"]
            or work_hours["work_end"] != Config.DEFAULT_WORK_HOURS["work_end"]
        )

    # ========== ç”¨æˆ·ç›¸å…³æ“ä½œ ==========
    async def init_user(
        self,
        chat_id: int,
        user_id: int,
        nickname: str = None,
        target_datetime: datetime = None,
    ):
        """åˆå§‹åŒ–ç”¨æˆ· - ä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ"""
        if target_datetime is None:
            target_datetime = self.get_beijing_time()

        # ğŸ¯ ä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ
        period_date = await self.get_reset_period_date(chat_id, target_datetime)

        await self.execute_with_retry(
            "åˆå§‹åŒ–ç”¨æˆ·",
            """
            INSERT INTO users (chat_id, user_id, nickname, last_updated) 
            VALUES ($1, $2, $3, $4) 
            ON CONFLICT (chat_id, user_id) 
            DO UPDATE SET 
                nickname = COALESCE($3, users.nickname),
                last_updated = $4,
                updated_at = CURRENT_TIMESTAMP
            """,
            chat_id,
            user_id,
            nickname,
            period_date,  # ğŸ¯ ä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ
        )
        self._cache.pop(f"user:{chat_id}:{user_id}", None)

    async def update_user_last_updated(
        self, chat_id: int, user_id: int, update_date: date
    ):
        """æ›´æ–°ç”¨æˆ·æœ€åæ›´æ–°æ—¶é—´"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "UPDATE users SET last_updated = $1 WHERE chat_id = $2 AND user_id = $3",
                update_date,
                chat_id,
                user_id,
            )

    async def get_user(self, chat_id: int, user_id: int) -> Optional[Dict]:
        cache_key = f"user:{chat_id}:{user_id}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        row = await self.execute_with_retry(
            "è·å–ç”¨æˆ·æ•°æ®",
            """
            SELECT user_id, nickname, current_activity, activity_start_time, 
                total_accumulated_time, total_activity_count, total_fines,
                overtime_count, total_overtime_time, last_updated
            FROM users WHERE chat_id = $1 AND user_id = $2
            """,
            chat_id,
            user_id,
            fetchrow=True,  # ğŸ¯ æ˜ç¡®æŒ‡å®šæŸ¥è¯¢ç±»å‹
            timeout=10,  # ğŸ¯ ç”¨æˆ·æŸ¥è¯¢è®¾ç½®è¾ƒçŸ­è¶…æ—¶
            slow_threshold=0.5,  # ğŸ¯ ç”¨æˆ·æŸ¥è¯¢è¦æ±‚æ›´é«˜æ€§èƒ½
        )

        if row:
            result = dict(row)
            self._set_cached(cache_key, result, 30)
            return result
        return None

    async def get_user_cached(
        self, chat_id: int, user_id: int, target_datetime: datetime = None
    ) -> Optional[Dict]:
        """
        å¸¦ç¼“å­˜çš„è·å–ç”¨æˆ·æ•°æ® - ä¿®å¤ç‰ˆï¼šä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ
        """

        if target_datetime is None:
            target_datetime = self.get_beijing_time()

        cache_key = f"user:{chat_id}:{user_id}"
        cached = self._get_cached(cache_key)

        # ğŸ¯ è·å–å½“å‰é‡ç½®å‘¨æœŸæ—¥æœŸï¼ˆè€Œä¸æ˜¯è‡ªç„¶æ—¥ï¼‰
        current_period_date = await self.get_reset_period_date(chat_id, target_datetime)

        # --- ğŸ¯ ç¼“å­˜å‘½ä¸­ä½†å¿…é¡»æ ¡éªŒå‘¨æœŸ ---
        if cached is not None:
            db_date = cached.get("last_updated")

            # æ—¥æœŸç±»å‹è½¬æ¢ï¼Œç¡®ä¿å¯æ¯”è¾ƒ
            if hasattr(db_date, "date"):
                db_date = db_date.date()

            # ğŸ¯ åªæœ‰åœ¨åŒä¸€é‡ç½®å‘¨æœŸå†…ï¼Œç¼“å­˜æ‰æœ‰æ•ˆ
            if db_date == current_period_date:
                return cached
            else:
                # ç¼“å­˜è·¨å‘¨æœŸï¼Œç«‹å³æ¸…ç†
                self._cache.pop(cache_key, None)

        # --- ğŸ¯ ä»æ•°æ®åº“è¯»å– ---
        row = await self.fetchrow_with_retry(
            "è·å–ç”¨æˆ·æ•°æ®",
            """
            SELECT 
                user_id,
                nickname,
                current_activity,
                activity_start_time,
                total_accumulated_time,
                total_activity_count,
                total_fines,
                overtime_count,
                total_overtime_time,
                last_updated
            FROM users 
            WHERE chat_id = $1 AND user_id = $2
            """,
            chat_id,
            user_id,
        )

        if row:
            result = dict(row)
            db_date = result.get("last_updated")

            # æ—¥æœŸç±»å‹è½¬æ¢
            if hasattr(db_date, "date"):
                db_date = db_date.date()

            # ğŸ¯ æ ¸å¿ƒå…œåº•ï¼šæ•°æ®åº“æ—¥æœŸä¸åœ¨å½“å‰é‡ç½®å‘¨æœŸ
            if db_date != current_period_date:
                result.update(
                    {
                        "total_accumulated_time": 0,
                        "total_activity_count": 0,
                        "total_fines": 0,
                        "overtime_count": 0,
                        "total_overtime_time": 0,
                        "current_activity": None,
                        "activity_start_time": None,
                        # ä»…ä¿®æ­£å†…å­˜æ•°æ®ï¼Œä¸å†™åº“
                        "last_updated": current_period_date,
                    }
                )

            self._set_cached(cache_key, result, 30)  # 30 ç§’ç¼“å­˜
            return result

        return None

    async def update_user_activity(
        self,
        chat_id: int,
        user_id: int,
        activity: str,
        start_time: str | datetime,
        nickname: str = None,
        target_datetime: datetime = None,
    ) -> int:
        """
        åŸå­æ€§æ›´æ–°ç”¨æˆ·æ´»åŠ¨çŠ¶æ€å¹¶è¿”å›æ›´æ–°åçš„è®¡æ•° - åŠ å¼ºç‰ˆ
        æ·»åŠ æ›´å¤šè°ƒè¯•æ—¥å¿—å’ŒéªŒè¯
        """
        try:
            # 1ï¸âƒ£ ç»Ÿä¸€æ—¶é—´å…¥å£
            if target_datetime is None:
                target_datetime = self.get_beijing_time()

            # 2ï¸âƒ£ è·å–ä¸šåŠ¡å‘¨æœŸæ—¥æœŸ
            period_date = await self.get_reset_period_date(chat_id, target_datetime)

            # ğŸ¯ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å‘¨æœŸä¿¡æ¯
            logger.debug(
                f"ğŸ” update_user_activity: {chat_id}-{user_id}-{activity}, "
                f"å‘¨æœŸæ—¥æœŸ: {period_date}, ç›®æ ‡æ—¶é—´: {target_datetime.strftime('%Y-%m-%d %H:%M:%S')}"
            )

            # 3ï¸âƒ£ æ ‡å‡†åŒ– start_time
            if hasattr(start_time, "isoformat"):
                if start_time.tzinfo is None:
                    start_time = beijing_tz.localize(start_time)
                start_time_str = start_time.isoformat()
            elif isinstance(start_time, str):
                start_time_str = self._normalize_time_string(
                    start_time, target_datetime
                )
            else:
                start_time_str = str(start_time)

            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                async with conn.transaction():
                    # ğŸ¯ è°ƒè¯•ï¼šæ£€æŸ¥å½“å‰æ˜¯å¦æœ‰è®°å½•
                    existing_record = await conn.fetchrow(
                        """
                        SELECT activity_count FROM user_activities 
                        WHERE chat_id = $1 AND user_id = $2 
                        AND activity_date = $3 AND activity_name = $4
                        """,
                        chat_id,
                        user_id,
                        period_date,
                        activity,
                    )

                    logger.debug(
                        f"ğŸ“Š æ›´æ–°å‰æ£€æŸ¥: {chat_id}-{user_id}-{activity}, "
                        f"ç°æœ‰è®°å½•: {'æœ‰' if existing_record else 'æ— '}, "
                        f"ç°æœ‰æ¬¡æ•°: {existing_record['activity_count'] if existing_record else 0}"
                    )

                    # 4ï¸âƒ£ åŸå­æ€§æ›´æ–° user_activities å¹¶è¿”å›æœ€æ–°è®¡æ•°
                    row = await conn.fetchrow(
                        """
                        INSERT INTO user_activities
                            (chat_id, user_id, activity_date, activity_name, activity_count, accumulated_time)
                        VALUES ($1, $2, $3, $4, 1, 0)
                        ON CONFLICT (chat_id, user_id, activity_date, activity_name)
                        DO UPDATE SET
                            activity_count = user_activities.activity_count + 1,
                            updated_at = CURRENT_TIMESTAMP
                        RETURNING activity_count
                        """,
                        chat_id,
                        user_id,
                        period_date,
                        activity,
                    )
                    updated_count = row["activity_count"] if row else 1

                    # 5ï¸âƒ£ æ›´æ–° users è¡¨ï¼ˆæ”¯æŒ nicknameï¼‰
                    update_query = """
                        UPDATE users
                        SET current_activity = $1,
                            activity_start_time = $2,
                            last_updated = $3,
                            updated_at = CURRENT_TIMESTAMP
                    """
                    update_params = [
                        activity,
                        start_time_str,
                        period_date,
                        chat_id,
                        user_id,
                    ]

                    if nickname:
                        update_query = update_query.replace(
                            "updated_at = CURRENT_TIMESTAMP",
                            "nickname = $6, updated_at = CURRENT_TIMESTAMP",
                        )
                        update_params.append(nickname)

                    update_query += " WHERE chat_id = $4 AND user_id = $5"
                    await conn.execute(update_query, *update_params)

                    # ğŸ¯ éªŒè¯æ›´æ–°
                    verify_row = await conn.fetchrow(
                        "SELECT activity_count FROM user_activities WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3 AND activity_name = $4",
                        chat_id,
                        user_id,
                        period_date,
                        activity,
                    )

                    if verify_row and verify_row["activity_count"] != updated_count:
                        logger.error(
                            f"âš ï¸ éªŒè¯å¤±è´¥: æœŸæœ›{updated_count}, å®é™…{verify_row['activity_count']}"
                        )

            # 6ï¸âƒ£ ç¼“å­˜æ¸…ç†ï¼ˆäº‹åŠ¡å¤–æ‰§è¡Œï¼‰
            cache_keys_to_remove = [
                f"user:{chat_id}:{user_id}",
                f"user_all_activities:{chat_id}:{user_id}",
                f"activity_count:{chat_id}:{user_id}:{activity}:{period_date}",
            ]

            # æ¸…ç†æ‰€æœ‰æ´»åŠ¨è®¡æ•°ç›¸å…³çš„ç¼“å­˜
            pattern = f"activity_count:{chat_id}:{user_id}:"
            for cache_key in list(self._cache.keys()):
                if cache_key.startswith(pattern):
                    cache_keys_to_remove.append(cache_key)

            for key in set(cache_keys_to_remove):  # å»é‡
                self._cache.pop(key, None)
                self._cache_ttl.pop(key, None)

            logger.info(
                f"âœ… ç”¨æˆ·æ´»åŠ¨æ›´æ–°: {chat_id}-{user_id}, æ´»åŠ¨: {activity}, "
                f"å‘¨æœŸ: {period_date}, è®¡æ•°: {updated_count}"
            )

            return updated_count

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç”¨æˆ·æ´»åŠ¨å¤±è´¥ {chat_id}-{user_id}: {e}")
            import traceback

            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            return 0

    # ===================== è¾…åŠ©æ–¹æ³•ï¼šæ—¶é—´æ ‡å‡†åŒ– =====================
    def _normalize_time_string(
        self, time_str: str, reference_time: datetime = None
    ) -> str:
        """æ ‡å‡†åŒ–æ—¶é—´å­—ç¬¦ä¸²ä¸º ISO æ ¼å¼"""
        try:

            clean_str = time_str.strip()

            # å¤„ç†æ—¶åŒº
            if clean_str.endswith("Z"):
                clean_str = clean_str.replace("Z", "+00:00")

            # å°è¯• ISO æ ¼å¼
            try:
                dt = datetime.fromisoformat(clean_str)
            except ValueError:
                # å°è¯•å¸¸è§æ ¼å¼
                formats = [
                    "%Y-%m-%d %H:%M:%S.%f",
                    "%Y-%m-%d %H:%M:%S",
                    "%Y-%m-%d %H:%M",
                    "%m/%d %H:%M:%S",
                    "%m/%d %H:%M",
                    "%H:%M:%S",
                    "%H:%M",
                ]

                for fmt in formats:
                    try:
                        dt = datetime.strptime(clean_str, fmt)
                        # è¡¥å……ç¼ºå¤±çš„æ—¥æœŸéƒ¨åˆ†
                        if fmt.startswith("%H:%M"):
                            dt = dt.replace(
                                year=reference_time.year,
                                month=reference_time.month,
                                day=reference_time.day,
                            )
                        elif fmt.startswith("%m/%d"):
                            dt = dt.replace(year=reference_time.year)
                        break
                    except ValueError:
                        continue
                else:
                    raise ValueError(f"æ— æ³•è§£ææ—¶é—´æ ¼å¼: {clean_str}")

            # ç¡®ä¿æœ‰æ—¶åŒº
            if dt.tzinfo is None:
                dt = beijing_tz.localize(dt)

            return dt.isoformat()

        except Exception as e:
            logger.warning(f"âš ï¸ æ—¶é—´æ ‡å‡†åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹å€¼: {e}")
            return time_str

    async def complete_user_activity(
        self,
        chat_id: int,
        user_id: int,
        activity: str,
        elapsed_time: int,
        fine_amount: int = 0,
        is_overtime: bool = False,
    ):
        """å®Œæˆç”¨æˆ·æ´»åŠ¨ - æœ€ç»ˆä¼˜åŒ–ç‰ˆï¼ˆä¿®å¤å­—æ®µé—®é¢˜ï¼‰"""
        # 1ï¸âƒ£ ç»Ÿä¸€æ—¶é—´å…¥å£
        current_time = self.get_beijing_time()
        period_date = await self.get_reset_period_date(chat_id, current_time)  # æ—¥å‘¨æœŸ
        statistic_date = current_time.date().replace(day=1)  # æœˆç»Ÿè®¡æ—¥æœŸ ğŸ¯ æ–°å¢

        # ä¿è¯ elapsed_time éè´Ÿ
        elapsed_time = max(0, elapsed_time)
        overtime_seconds = 0

        if is_overtime:
            time_limit = await self.get_activity_time_limit(activity)
            time_limit_seconds = time_limit * 60
            overtime_seconds = max(0, elapsed_time - time_limit_seconds)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            try:
                async with conn.transaction():
                    # --- A. ç¡®ä¿ users è¡¨å­˜åœ¨è®°å½•ï¼ˆä½¿ç”¨å‘¨æœŸæ—¥æœŸï¼‰---
                    await conn.execute(
                        """
                        INSERT INTO users (chat_id, user_id, last_updated)
                        VALUES ($1, $2, $3)
                        ON CONFLICT (chat_id, user_id)
                        DO UPDATE SET last_updated = EXCLUDED.last_updated
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )

                    # --- B. user_activities æ—¥æµæ°´ç´¯åŠ  ---
                    await conn.execute(
                        """
                        INSERT INTO user_activities
                        (chat_id, user_id, activity_date, activity_name, activity_count, accumulated_time)
                        VALUES ($1, $2, $3, $4, 1, $5)
                        ON CONFLICT (chat_id, user_id, activity_date, activity_name)
                        DO UPDATE SET
                            activity_count = user_activities.activity_count + 1,
                            accumulated_time = user_activities.accumulated_time + EXCLUDED.accumulated_time,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        chat_id,
                        user_id,
                        period_date,
                        activity,
                        elapsed_time,
                    )

                    # --- C. monthly_statistics æœˆåº¦ç´¯åŠ ï¼ˆä½¿ç”¨ statistic_dateï¼‰---
                    await conn.execute(
                        """
                        INSERT INTO monthly_statistics
                        (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                        VALUES ($1, $2, $3, $4, 1, $5)
                        ON CONFLICT (chat_id, user_id, statistic_date, activity_name)
                        DO UPDATE SET
                            activity_count = monthly_statistics.activity_count + 1,
                            accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                            updated_at = CURRENT_TIMESTAMP
                        """,
                        chat_id,
                        user_id,
                        statistic_date,
                        activity,
                        elapsed_time,
                    )

                    # --- D. è¶…æ—¶ç»Ÿè®¡ï¼ˆåˆå¹¶æ›´æ–°ï¼‰---
                    if is_overtime and overtime_seconds > 0:
                        await conn.execute(
                            """
                            INSERT INTO monthly_statistics
                            (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                            VALUES
                            ($1, $2, $3, 'overtime_count', 1, 0),
                            ($1, $2, $3, 'overtime_time', 0, $4)
                            ON CONFLICT (chat_id, user_id, statistic_date, activity_name)
                            DO UPDATE SET
                                activity_count = monthly_statistics.activity_count + EXCLUDED.activity_count,
                                accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                                updated_at = CURRENT_TIMESTAMP
                            """,
                            chat_id,
                            user_id,
                            statistic_date,
                            overtime_seconds,
                        )

                    # --- E. ç½šæ¬¾ç»Ÿè®¡ ---
                    if fine_amount > 0:
                        await conn.execute(
                            """
                            INSERT INTO monthly_statistics
                            (chat_id, user_id, statistic_date, activity_name, accumulated_time)
                            VALUES ($1, $2, $3, 'total_fines', $4)
                            ON CONFLICT (chat_id, user_id, statistic_date, activity_name)
                            DO UPDATE SET
                                accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                                updated_at = CURRENT_TIMESTAMP
                            """,
                            chat_id,
                            user_id,
                            statistic_date,
                            fine_amount,
                        )

                    # --- F. users ä¸»è¡¨ç´¯è®¡æ›´æ–° ---
                    update_fields = [
                        "total_accumulated_time = total_accumulated_time + $1",
                        "total_activity_count = total_activity_count + 1",
                        "current_activity = NULL",
                        "activity_start_time = NULL",
                        "last_updated = $2",
                        "updated_at = CURRENT_TIMESTAMP",
                    ]
                    params = [elapsed_time, period_date]
                    idx = 3

                    if fine_amount > 0:
                        update_fields.append(f"total_fines = total_fines + ${idx}")
                        params.append(fine_amount)
                        idx += 1

                    if is_overtime:
                        update_fields.append("overtime_count = overtime_count + 1")
                        update_fields.append(
                            f"total_overtime_time = total_overtime_time + ${idx}"
                        )
                        params.append(overtime_seconds)
                        idx += 1

                    params.extend([chat_id, user_id])
                    query = f"UPDATE users SET {', '.join(update_fields)} WHERE chat_id = ${idx} AND user_id = ${idx+1}"
                    await conn.execute(query, *params)

            finally:
                # --- G. ç¼“å­˜æ¸…ç†ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰---
                cache_keys = [
                    f"user:{chat_id}:{user_id}",
                    f"user_all_activities:{chat_id}:{user_id}",
                ]
                for key in cache_keys:
                    self._cache.pop(key, None)

        logger.info(f"âœ… ç”¨æˆ· {user_id} æ´»åŠ¨å®Œæˆ: {activity} (æ—¶é•¿: {elapsed_time}ç§’)")

    # ========= é‡ç½®å‰æ‰¹é‡å®Œæˆæ‰€æœ‰æœªç»“æŸæ´»åŠ¨ =========
    async def complete_all_pending_activities_before_reset(
        self, chat_id: int, reset_time: datetime
    ) -> Dict[str, Any]:
        """åœ¨é‡ç½®å‰æ‰¹é‡å®Œæˆæ‰€æœ‰æœªç»“æŸæ´»åŠ¨ - å®Œæ•´ç‰ˆæœ¬"""
        try:
            completed_count = 0
            total_fines = 0

            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                async with conn.transaction():
                    # ğŸ¯ æ‰¹é‡è·å–æ‰€æœ‰æœªç»“æŸæ´»åŠ¨
                    active_users = await conn.fetch(
                        """
                        SELECT user_id, nickname, current_activity, activity_start_time 
                        FROM users 
                        WHERE chat_id = $1 AND current_activity IS NOT NULL
                    """,
                        chat_id,
                    )

                    if not active_users:
                        return {"completed_count": 0, "total_fines": 0, "details": []}

                    completion_details = []
                    statistic_date = reset_time.date().replace(day=1)

                    for user in active_users:
                        user_id = user["user_id"]
                        nickname = user["nickname"]
                        activity = user["current_activity"]
                        start_time_str = user["activity_start_time"]

                        try:
                            # è§£æå¼€å§‹æ—¶é—´
                            start_time = datetime.fromisoformat(start_time_str)

                            # è®¡ç®—æ´»åŠ¨æ—¶é•¿ï¼ˆåˆ°é‡ç½®æ—¶é—´ä¸ºæ­¢ï¼‰
                            elapsed = int((reset_time - start_time).total_seconds())

                            # è®¡ç®—è¶…æ—¶å’Œç½šæ¬¾
                            time_limit = await self.get_activity_time_limit(activity)
                            time_limit_seconds = time_limit * 60
                            is_overtime = elapsed > time_limit_seconds
                            overtime_seconds = max(0, elapsed - time_limit_seconds)
                            overtime_minutes = overtime_seconds / 60

                            fine_amount = 0
                            if is_overtime and overtime_seconds > 0:
                                fine_amount = await self.calculate_fine_for_activity(
                                    activity, overtime_minutes
                                )

                            # ğŸ¯ æ›´æ–°æœˆåº¦ç»Ÿè®¡è¡¨
                            await self._update_monthly_statistics_for_activity(
                                conn,
                                chat_id,
                                user_id,
                                statistic_date,
                                activity,
                                elapsed,
                                fine_amount,
                                is_overtime,
                                overtime_seconds,
                            )

                            completed_count += 1
                            total_fines += fine_amount

                            completion_details.append(
                                {
                                    "user_id": user_id,
                                    "nickname": nickname,
                                    "activity": activity,
                                    "elapsed_time": elapsed,
                                    "fine_amount": fine_amount,
                                    "is_overtime": is_overtime,
                                }
                            )

                            logger.info(
                                f"é‡ç½®å‰ç»“æŸæ´»åŠ¨: {chat_id}-{user_id} - {activity} (æ—¶é•¿: {elapsed}ç§’, ç½šæ¬¾: {fine_amount}å…ƒ)"
                            )

                        except Exception as e:
                            logger.error(f"ç»“æŸç”¨æˆ·æ´»åŠ¨å¤±è´¥ {chat_id}-{user_id}: {e}")
                            # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–ç”¨æˆ·

                    # ğŸ¯ æ‰¹é‡æ¸…ç©ºæ´»åŠ¨çŠ¶æ€
                    await conn.execute(
                        """
                        UPDATE users 
                        SET current_activity = NULL, activity_start_time = NULL 
                        WHERE chat_id = $1 AND current_activity IS NOT NULL
                    """,
                        chat_id,
                    )

                    return {
                        "completed_count": completed_count,
                        "total_fines": total_fines,
                        "details": completion_details,
                    }

        except Exception as e:
            logger.error(f"æ‰¹é‡ç»“æŸæ´»åŠ¨å¤±è´¥ {chat_id}: {e}")
            return {"completed_count": 0, "total_fines": 0, "details": []}

    async def _update_monthly_statistics_for_activity(
        self,
        conn,
        chat_id: int,
        user_id: int,
        statistic_date: date,
        activity: str,
        elapsed: int,
        fine_amount: int,
        is_overtime: bool,
        overtime_seconds: int,
    ):
        """æ›´æ–°æœˆåº¦ç»Ÿè®¡çš„è¾…åŠ©æ–¹æ³•"""
        # æ›´æ–°æ´»åŠ¨ç»Ÿè®¡
        await conn.execute(
            """
            INSERT INTO monthly_statistics 
            (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
            VALUES ($1, $2, $3, $4, 1, $5)
            ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
            DO UPDATE SET 
                activity_count = monthly_statistics.activity_count + 1,
                accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                updated_at = CURRENT_TIMESTAMP
        """,
            chat_id,
            user_id,
            statistic_date,
            activity,
            elapsed,
        )

        # æ›´æ–°ç½šæ¬¾ç»Ÿè®¡
        if fine_amount > 0:
            await conn.execute(
                """
                INSERT INTO monthly_statistics 
                (chat_id, user_id, statistic_date, activity_name, accumulated_time)
                VALUES ($1, $2, $3, 'total_fines', $4)
                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                DO UPDATE SET 
                    accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                    updated_at = CURRENT_TIMESTAMP
            """,
                chat_id,
                user_id,
                statistic_date,
                fine_amount,
            )

        # æ›´æ–°è¶…æ—¶ç»Ÿè®¡
        if is_overtime:
            await conn.execute(
                """
                INSERT INTO monthly_statistics 
                (chat_id, user_id, statistic_date, activity_name, activity_count)
                VALUES ($1, $2, $3, 'overtime_count', 1)
                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                DO UPDATE SET 
                    activity_count = monthly_statistics.activity_count + 1,
                    updated_at = CURRENT_TIMESTAMP
            """,
                chat_id,
                user_id,
                statistic_date,
            )

            await conn.execute(
                """
                INSERT INTO monthly_statistics 
                (chat_id, user_id, statistic_date, activity_name, accumulated_time)
                VALUES ($1, $2, $3, 'overtime_time', $4)
                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                DO UPDATE SET 
                    accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                    updated_at = CURRENT_TIMESTAMP
            """,
                chat_id,
                user_id,
                statistic_date,
                overtime_seconds,
            )

    async def reset_user_daily_data(
        self,
        chat_id: int,
        user_id: int,
        target_datetime: Optional[datetime] = None,
    ) -> bool:
        """å½»åº•é‡ç½®ç”¨æˆ·æ¯æ—¥æ•°æ®ï¼šä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ + æ•°æ®å®‰å…¨"""

        try:
            # ğŸ¯ 1. ç»Ÿä¸€æ—¶é—´å…¥å£
            if target_datetime is None:
                target_datetime = self.get_beijing_time()

            # ğŸ¯ 2. è·å–ä¸šåŠ¡é‡ç½®å‘¨æœŸæ—¥æœŸ
            period_date = await self.get_reset_period_date(chat_id, target_datetime)

            # ğŸ¯ è°ƒè¯•ï¼šè®°å½•é‡ç½®å¼€å§‹
            logger.info(
                f"ğŸ”„ å¼€å§‹é‡ç½®ç”¨æˆ·æ•°æ®: {chat_id}-{user_id}, "
                f"å‘¨æœŸæ—¥æœŸ: {period_date}, "
                f"ç›®æ ‡æ—¶é—´: {target_datetime.strftime('%Y-%m-%d %H:%M:%S')}"
            )

            # ğŸ¯ 3. ç¡®ä¿ç”¨æˆ·å­˜åœ¨ä¸” last_updated å¯¹é½å‘¨æœŸ
            await self.init_user(chat_id, user_id, None, target_datetime)

            self._ensure_pool_initialized()

            async with self.pool.acquire() as conn:
                async with conn.transaction():
                    # ğŸ¯ è°ƒè¯•ï¼šé‡ç½®å‰æ£€æŸ¥æ•°æ®
                    pre_reset_check = await conn.fetchrow(
                        """
                        SELECT 
                            (SELECT COUNT(*) FROM user_activities 
                             WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3) as activity_count,
                            (SELECT COUNT(*) FROM work_records 
                             WHERE chat_id = $1 AND user_id = $2 AND record_date = $3) as work_record_count,
                            (SELECT total_activity_count FROM users 
                             WHERE chat_id = $1 AND user_id = $2) as user_total_count
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )

                    logger.debug(
                        f"ğŸ“Š é‡ç½®å‰æ•°æ®çŠ¶æ€: "
                        f"æ´»åŠ¨è®°å½•æ•°={pre_reset_check['activity_count']}, "
                        f"å·¥ä½œè®°å½•æ•°={pre_reset_check['work_record_count']}, "
                        f"ç”¨æˆ·æ€»æ¬¡æ•°={pre_reset_check['user_total_count']}"
                    )

                    # --- ğŸ§¹ A: åˆ é™¤å½“æœŸæ´»åŠ¨æµæ°´ ---
                    delete_result = await conn.execute(
                        """
                        DELETE FROM user_activities
                        WHERE chat_id = $1
                          AND user_id = $2
                          AND activity_date = $3
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )
                    logger.debug(f"åˆ é™¤æ´»åŠ¨è®°å½•ç»“æœ: {delete_result}")

                    # --- ğŸ§¹ B: åˆ é™¤å½“æœŸä¸Šä¸‹ç­è®°å½• ---
                    delete_work_result = await conn.execute(
                        """
                        DELETE FROM work_records
                        WHERE chat_id = $1
                          AND user_id = $2
                          AND record_date = $3
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )
                    logger.debug(f"åˆ é™¤å·¥ä½œè®°å½•ç»“æœ: {delete_work_result}")

                    # --- ğŸ§® C: ä¸»è¡¨å½»åº•å½’é›¶ ---
                    update_result = await conn.execute(
                        """
                        UPDATE users SET
                            total_activity_count = 0,
                            total_accumulated_time = 0,
                            total_fines = 0,
                            total_overtime_time = 0,
                            overtime_count = 0,
                            current_activity = NULL,
                            activity_start_time = NULL,
                            last_updated = $3,
                            updated_at = CURRENT_TIMESTAMP
                        WHERE chat_id = $1
                          AND user_id = $2
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )
                    logger.debug(f"æ›´æ–°ç”¨æˆ·è¡¨ç»“æœ: {update_result}")

                    # ğŸ¯ éªŒè¯é‡ç½®æ•ˆæœ
                    post_reset_check = await conn.fetchrow(
                        """
                        SELECT 
                            (SELECT COUNT(*) FROM user_activities 
                             WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3) as activity_count,
                            (SELECT total_activity_count FROM users 
                             WHERE chat_id = $1 AND user_id = $2) as user_total_count
                        """,
                        chat_id,
                        user_id,
                        period_date,
                    )

                    if (
                        post_reset_check["activity_count"] > 0
                        or post_reset_check["user_total_count"] > 0
                    ):
                        logger.warning(
                            f"âš ï¸ é‡ç½®åæ•°æ®éé›¶: "
                            f"æ´»åŠ¨è®°å½•æ•°={post_reset_check['activity_count']}, "
                            f"ç”¨æˆ·æ€»æ¬¡æ•°={post_reset_check['user_total_count']}"
                        )

                # ğŸ¯ æäº¤äº‹åŠ¡åï¼Œç¡®ä¿ç”¨æˆ·æ•°æ®è¢«æ­£ç¡®æ›´æ–°
                await conn.execute(
                    """
                    UPDATE users SET last_updated = $3 
                    WHERE chat_id = $1 AND user_id = $2
                    """,
                    chat_id,
                    user_id,
                    period_date,
                )

            # --- ğŸ§½ D: ç¼“å­˜æ¸…ç† ---
            cache_keys_to_remove = set()

            # 1. å›ºå®šè¦æ¸…ç†çš„é”®
            fixed_keys = [
                f"user:{chat_id}:{user_id}",
                f"user_all_activities:{chat_id}:{user_id}",
                f"group:{chat_id}",
            ]
            cache_keys_to_remove.update(fixed_keys)

            # 2. åŠ¨æ€åŒ¹é…è¦æ¸…ç†çš„é”®
            all_cache_keys = list(self._cache.keys())
            for cache_key in all_cache_keys:
                if f"activity_count:{chat_id}:{user_id}:" in cache_key:
                    cache_keys_to_remove.add(cache_key)
                if f"activity_limit:" in cache_key:
                    cache_keys_to_remove.add(cache_key)

            # 3. æ‰§è¡Œæ¸…ç†
            cleaned_count = 0
            for key in cache_keys_to_remove:
                if key in self._cache:
                    self._cache.pop(key, None)
                    cleaned_count += 1
                if key in self._cache_ttl:
                    self._cache_ttl.pop(key, None)

            logger.info(f"ğŸ§¹ ç¼“å­˜æ¸…ç†: æ¸…ç†äº† {cleaned_count} ä¸ªç¼“å­˜é¡¹")

            # ğŸ¯ é‡ç½®åç«‹å³éªŒè¯
            try:
                async with self.pool.acquire() as conn:
                    verify_row = await conn.fetchrow(
                        """
                        SELECT activity_count FROM user_activities 
                        WHERE chat_id = $1 AND user_id = $2 
                        AND activity_date = $3 AND activity_name = $4
                        """,
                        chat_id,
                        user_id,
                        period_date,
                        "å°å•",  # ç¤ºä¾‹æ´»åŠ¨ï¼Œå¯æŒ‰å®é™…è°ƒæ•´
                    )
                    verify_count = verify_row["activity_count"] if verify_row else 0

                    if verify_count == 0:
                        logger.info(
                            f"âœ… é‡ç½®éªŒè¯é€šè¿‡: {chat_id}-{user_id}, æ´»åŠ¨è®¡æ•°={verify_count}"
                        )
                    else:
                        logger.warning(
                            f"âš ï¸ é‡ç½®éªŒè¯å¼‚å¸¸: {chat_id}-{user_id}, æ´»åŠ¨è®¡æ•°={verify_count} (åº”è¯¥æ˜¯0)"
                        )
            except Exception as verify_error:
                logger.error(f"âŒ é‡ç½®éªŒè¯å¤±è´¥: {verify_error}")

            logger.info(f"âœ… æ•°æ®é‡ç½®å®Œæˆ: {chat_id}-{user_id}, å‘¨æœŸ={period_date}")
            return True

        except Exception as e:
            logger.error(f"âŒ é‡ç½®å¤±è´¥ {chat_id}-{user_id}: {e}")
            import traceback

            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return False

    async def get_user_activity_count(
        self,
        chat_id: int,
        user_id: int,
        activity: str,
        target_datetime: datetime = None,
        cache_ttl: int = 3,  # çŸ­æœŸç¼“å­˜ç§’æ•°ï¼Œå¯è°ƒæ•´
    ) -> int:

        try:
            # 1ï¸âƒ£ ç»Ÿä¸€æ—¶é—´å…¥å£
            if target_datetime is None:
                target_datetime = self.get_beijing_time()

            # 2ï¸âƒ£ è·å–ä¸šåŠ¡å‘¨æœŸæ—¥æœŸ
            period_date = await self.get_reset_period_date(chat_id, target_datetime)

            # 3ï¸âƒ£ æ„é€ ç¼“å­˜ keyï¼ˆä¸ update_user_activity ä¿æŒä¸€è‡´ï¼‰
            cache_key = f"activity_count:{chat_id}:{user_id}:{activity}:{period_date}"

            # ğŸ¯ è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å…³é”®ä¿¡æ¯
            logger.debug(
                f"ğŸ” get_user_activity_count: {cache_key}, "
                f"å‘¨æœŸ: {period_date}, æ—¶é—´: {target_datetime.strftime('%Y-%m-%d %H:%M:%S')}"
            )

            current_time = time.time()

            # 4ï¸âƒ£ æ£€æŸ¥ç¼“å­˜æœ‰æ•ˆæ€§
            if cache_key in self._cache_ttl:
                if current_time < self._cache_ttl[cache_key]:
                    cached_value = self._cache.get(cache_key)
                    if cached_value is not None:
                        logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_key} = {cached_value}")
                        return cached_value
                else:
                    # TTL è¿‡æœŸï¼Œæ¸…ç†ç¼“å­˜
                    logger.debug(f"ğŸ”„ ç¼“å­˜è¿‡æœŸ: {cache_key}")
                    self._cache.pop(cache_key, None)
                    self._cache_ttl.pop(cache_key, None)

            # 5ï¸âƒ£ æŸ¥è¯¢æ•°æ®åº“
            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                row = await conn.fetchrow(
                    """
                    SELECT activity_count 
                    FROM user_activities 
                    WHERE chat_id = $1 
                      AND user_id = $2 
                      AND activity_date = $3 
                      AND activity_name = $4
                    """,
                    chat_id,
                    user_id,
                    period_date,
                    activity,
                )
                count = row["activity_count"] if row else 0

            # 6ï¸âƒ£ è®¾ç½®çŸ­æœŸç¼“å­˜
            self._cache[cache_key] = count
            self._cache_ttl[cache_key] = current_time + cache_ttl

            logger.debug(f"ğŸ“Š æ•°æ®åº“æŸ¥è¯¢: {cache_key} = {count}")
            return count

        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·æ´»åŠ¨æ¬¡æ•°å¤±è´¥ {chat_id}-{user_id}-{activity}: {e}")
            import traceback

            logger.error(f"å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
            return 0

    async def get_user_all_activities(
        self, chat_id: int, user_id: int, target_datetime: datetime = None
    ) -> Dict[str, Dict]:
        """è·å–ç”¨æˆ·å½“å‰é‡ç½®å‘¨æœŸå†…çš„æ‰€æœ‰æ´»åŠ¨æ•°æ®"""
        try:
            # ğŸ¯ ä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸï¼Œè€Œä¸æ˜¯è‡ªç„¶æ—¥
            period_date = await self.get_reset_period_date(chat_id, target_datetime)

            self._ensure_pool_initialized()
            async with self.pool.acquire() as conn:
                rows = await conn.fetch(
                    """
                    SELECT activity_name, activity_count, accumulated_time 
                    FROM user_activities 
                    WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3
                    """,
                    chat_id,
                    user_id,
                    period_date,  # ğŸ¯ å…³é”®ï¼šä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ
                )

                activities = {}
                for row in rows:
                    activities[row["activity_name"]] = {
                        "count": row["activity_count"],
                        "time": row["accumulated_time"],
                    }
                return activities

        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·æ‰€æœ‰æ´»åŠ¨æ•°æ®å¤±è´¥ {chat_id}-{user_id}: {e}")
            return {}

    # ========== ä¸Šä¸‹ç­è®°å½•æ“ä½œ ==========
    async def add_work_record(
        self,
        chat_id: int,
        user_id: int,
        record_date,
        checkin_type: str,
        checkin_time: str,
        status: str,
        time_diff_minutes: float,
        fine_amount: int = 0,
    ):
        """æ·»åŠ ä¸Šä¸‹ç­è®°å½• - ä¿®å¤ç‰ˆ"""
        if isinstance(record_date, str):
            record_date = datetime.strptime(record_date, "%Y-%m-%d").date()
        elif isinstance(record_date, datetime):
            record_date = record_date.date()

        statistic_date = record_date.replace(day=1)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                # æ·»åŠ ä¸Šä¸‹ç­è®°å½•
                await conn.execute(
                    """
                    INSERT INTO work_records 
                    (chat_id, user_id, record_date, checkin_type, checkin_time, status, time_diff_minutes, fine_amount)
                    VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                    ON CONFLICT (chat_id, user_id, record_date, checkin_type) 
                    DO UPDATE SET 
                        checkin_time = EXCLUDED.checkin_time,
                        status = EXCLUDED.status,
                        time_diff_minutes = EXCLUDED.time_diff_minutes,
                        fine_amount = EXCLUDED.fine_amount,
                        created_at = CURRENT_TIMESTAMP
                    """,
                    chat_id,
                    user_id,
                    record_date,
                    checkin_type,
                    checkin_time,
                    status,
                    time_diff_minutes,
                    fine_amount,
                )

                # ğŸ†• ä¿®å¤ï¼šå®Œæ•´çš„å·¥ä½œå¤©æ•°å’Œå·¥ä½œæ—¶é•¿ç»Ÿè®¡
                if checkin_type == "work_end":
                    # è·å–å¯¹åº”çš„ä¸Šç­è®°å½•
                    work_start_record = await conn.fetchrow(
                        "SELECT checkin_time FROM work_records WHERE chat_id = $1 AND user_id = $2 AND record_date = $3 AND checkin_type = 'work_start'",
                        chat_id,
                        user_id,
                        record_date,
                    )

                    if work_start_record:
                        try:
                            # è®¡ç®—å·¥ä½œæ—¶é•¿
                            start_time_str = work_start_record["checkin_time"]
                            end_time_str = checkin_time

                            # è§£ææ—¶é—´ï¼ˆæ ¼å¼ä¸º HH:MMï¼‰
                            start_time = datetime.strptime(start_time_str, "%H:%M")
                            end_time = datetime.strptime(end_time_str, "%H:%M")

                            # è®¡ç®—å·¥ä½œæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
                            work_duration_minutes = (
                                end_time - start_time
                            ).total_seconds() / 60

                            # å¤„ç†è·¨å¤©æƒ…å†µï¼ˆå¦‚æœä¸‹ç­æ—¶é—´å°äºä¸Šç­æ—¶é—´ï¼Œè¯´æ˜è·¨å¤©äº†ï¼‰
                            if work_duration_minutes < 0:
                                work_duration_minutes += 24 * 60  # åŠ ä¸Š24å°æ—¶

                            # è½¬æ¢ä¸ºç§’
                            work_duration_seconds = int(work_duration_minutes * 60)

                            # ğŸ†• æ›´æ–°å·¥ä½œå¤©æ•°åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                                VALUES ($1, $2, $3, 'work_days', 1, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    activity_count = monthly_statistics.activity_count + 1,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                            )

                            # ğŸ†• æ›´æ–°å·¥ä½œæ—¶é•¿åˆ°æœˆåº¦ç»Ÿè®¡è¡¨
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, accumulated_time, activity_count)
                                VALUES ($1, $2, $3, 'work_hours', $4, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    accumulated_time = monthly_statistics.accumulated_time + EXCLUDED.accumulated_time,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                                work_duration_seconds,
                            )

                            logger.info(
                                f"å·¥ä½œç»Ÿè®¡æ›´æ–°: ç”¨æˆ·{user_id} å·¥ä½œæ—¶é•¿{work_duration_minutes:.1f}åˆ†é’Ÿ"
                            )

                        except Exception as e:
                            logger.error(f"è®¡ç®—å·¥ä½œæ—¶é•¿å¤±è´¥: {e}")
                            # å³ä½¿è®¡ç®—å¤±è´¥ï¼Œä¹Ÿè®°å½•å·¥ä½œå¤©æ•°ï¼ˆä½†ä¸è®°å½•æ—¶é•¿ï¼‰
                            await conn.execute(
                                """
                                INSERT INTO monthly_statistics 
                                (chat_id, user_id, statistic_date, activity_name, activity_count, accumulated_time)
                                VALUES ($1, $2, $3, 'work_days', 1, 0)
                                ON CONFLICT (chat_id, user_id, statistic_date, activity_name) 
                                DO UPDATE SET 
                                    activity_count = monthly_statistics.activity_count + 1,
                                    updated_at = CURRENT_TIMESTAMP
                                """,
                                chat_id,
                                user_id,
                                statistic_date,
                            )

                # æ›´æ–°ç½šæ¬¾ç»Ÿè®¡
                if fine_amount > 0:
                    await conn.execute(
                        "UPDATE users SET total_fines = total_fines + $1 WHERE chat_id = $2 AND user_id = $3",
                        fine_amount,
                        chat_id,
                        user_id,
                    )

            self._cache.pop(f"user:{chat_id}:{user_id}", None)

    # ========== æ´»åŠ¨é…ç½®æ“ä½œ ==========
    async def get_activity_limits(self) -> Dict:
        """è·å–æ‰€æœ‰æ´»åŠ¨é™åˆ¶ - ä¼˜åŒ–ç‰ˆ"""
        # ä½¿ç”¨æ›´é•¿çš„ç¼“å­˜æ—¶é—´ï¼Œå› ä¸ºè¿™äº›æ•°æ®ä¸å¸¸å˜åŒ–
        cache_key = "activity_limits"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        # æ£€æŸ¥æ•°æ®åº“è¿æ¥çŠ¶æ€
        if not await self._ensure_healthy_connection():
            logger.warning("æ•°æ®åº“è¿æ¥ä¸å¥åº·ï¼Œè¿”å›é»˜è®¤æ´»åŠ¨é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

        try:
            # ä½¿ç”¨æ›´å¿«çš„æŸ¥è¯¢ï¼Œåªè·å–éœ€è¦çš„å­—æ®µ
            rows = await self.fetch_with_retry(
                "è·å–æ´»åŠ¨é™åˆ¶",
                "SELECT activity_name, max_times, time_limit FROM activity_configs",
            )
            limits = {
                row["activity_name"]: {
                    "max_times": row["max_times"],
                    "time_limit": row["time_limit"],
                }
                for row in rows
            }
            # è®¾ç½®è¾ƒé•¿ç¼“å­˜æ—¶é—´ï¼Œå› ä¸ºæ´»åŠ¨é…ç½®ä¸å¸¸å˜åŒ–
            self._set_cached(cache_key, limits, 600)  # 10åˆ†é’Ÿç¼“å­˜
            return limits
        except Exception as e:
            logger.error(f"è·å–æ´»åŠ¨é…ç½®å¤±è´¥: {e}ï¼Œè¿”å›é»˜è®¤é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

    async def get_activity_limits_cached(self) -> Dict:
        """å¸¦ç¼“å­˜çš„è·å–æ´»åŠ¨é™åˆ¶"""
        try:
            return await self.get_activity_limits()
        except Exception as e:
            logger.error(f"è·å–æ´»åŠ¨é…ç½®ç¼“å­˜å¤±è´¥: {e}ï¼Œè¿”å›é»˜è®¤é…ç½®")
            return Config.DEFAULT_ACTIVITY_LIMITS.copy()

    async def get_activity_time_limit(self, activity: str) -> int:
        """è·å–æ´»åŠ¨æ—¶é—´é™åˆ¶"""
        limits = await self.get_activity_limits()
        return limits.get(activity, {}).get("time_limit", 0)

    async def get_activity_max_times(self, activity: str) -> int:
        """è·å–æ´»åŠ¨æœ€å¤§æ¬¡æ•°"""
        limits = await self.get_activity_limits()
        return limits.get(activity, {}).get("max_times", 0)

    async def activity_exists(self, activity: str) -> bool:
        """æ£€æŸ¥æ´»åŠ¨æ˜¯å¦å­˜åœ¨"""
        cache_key = "activity_limits"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return activity in cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT 1 FROM activity_configs WHERE activity_name = $1", activity
            )
            return row is not None

    async def update_activity_config(
        self, activity: str, max_times: int, time_limit: int
    ):
        """æ›´æ–°æ´»åŠ¨é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO activity_configs (activity_name, max_times, time_limit)
                VALUES ($1, $2, $3)
                ON CONFLICT (activity_name) 
                DO UPDATE SET 
                    max_times = EXCLUDED.max_times,
                    time_limit = EXCLUDED.time_limit,
                    created_at = CURRENT_TIMESTAMP
                """,
                activity,
                max_times,
                time_limit,
            )
        self._cache.pop("activity_limits", None)

    async def delete_activity_config(self, activity: str):
        """åˆ é™¤æ´»åŠ¨é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM activity_configs WHERE activity_name = $1", activity
            )
            await conn.execute(
                "DELETE FROM fine_configs WHERE activity_name = $1", activity
            )
        self._cache.pop("activity_limits", None)

    # ========== ç½šæ¬¾é…ç½®æ“ä½œ ==========
    async def get_fine_rates(self) -> Dict:
        """è·å–æ‰€æœ‰ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM fine_configs")
            fines = {}
            for row in rows:
                activity = row["activity_name"]
                if activity not in fines:
                    fines[activity] = {}
                fines[activity][row["time_segment"]] = row["fine_amount"]
            return fines

    async def get_fine_rates_for_activity(self, activity: str) -> Dict:
        """è·å–æŒ‡å®šæ´»åŠ¨çš„ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT time_segment, fine_amount FROM fine_configs WHERE activity_name = $1",
                activity,
            )
            return {row["time_segment"]: row["fine_amount"] for row in rows}

    async def update_fine_config(
        self, activity: str, time_segment: str, fine_amount: int
    ):
        """æ›´æ–°ç½šæ¬¾é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO fine_configs (activity_name, time_segment, fine_amount)
                VALUES ($1, $2, $3)
                ON CONFLICT (activity_name, time_segment) 
                DO UPDATE SET 
                    fine_amount = EXCLUDED.fine_amount,
                    created_at = CURRENT_TIMESTAMP
                """,
                activity,
                time_segment,
                fine_amount,
            )

    async def calculate_fine_for_activity(
        self, activity: str, overtime_minutes: float
    ) -> int:
        """è®¡ç®—æ´»åŠ¨ç½šæ¬¾é‡‘é¢ - æ•°æ®åº“å†…éƒ¨ç‰ˆæœ¬"""
        fine_rates = await self.get_fine_rates_for_activity(activity)
        if not fine_rates:
            return 0

        # å¤„ç†ç½šæ¬¾æ—¶é—´æ®µ
        segments = []
        for time_key in fine_rates.keys():
            try:
                if isinstance(time_key, str) and "min" in time_key.lower():
                    time_value = int(time_key.lower().replace("min", "").strip())
                else:
                    time_value = int(time_key)
                segments.append(time_value)
            except (ValueError, TypeError):
                continue

        if not segments:
            return 0

        segments.sort()

        applicable_fine = 0
        for segment in segments:
            if overtime_minutes <= segment:
                original_key = str(segment)
                if original_key not in fine_rates:
                    original_key = f"{segment}min"
                applicable_fine = fine_rates.get(original_key, 0)
                break

        if applicable_fine == 0 and segments:
            max_segment = segments[-1]
            original_key = str(max_segment)
            if original_key not in fine_rates:
                original_key = f"{max_segment}min"
            applicable_fine = fine_rates.get(original_key, 0)

        return applicable_fine

    async def get_work_fine_rates(self) -> Dict:
        """è·å–ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM work_fine_configs")
            fines = {}
            for row in rows:
                checkin_type = row["checkin_type"]
                if checkin_type not in fines:
                    fines[checkin_type] = {}
                fines[checkin_type][row["time_segment"]] = row["fine_amount"]
            return fines

    async def get_work_fine_rates_for_type(self, checkin_type: str) -> Dict:
        """è·å–æŒ‡å®šç±»å‹çš„ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT time_segment, fine_amount FROM work_fine_configs WHERE checkin_type = $1",
                checkin_type,
            )
            return {row["time_segment"]: row["fine_amount"] for row in rows}

    async def update_work_fine_rate(
        self, checkin_type: str, time_segment: str, fine_amount: int
    ):
        """æ›´æ–°ä¸Šä¸‹ç­ç½šæ¬¾è´¹ç‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO work_fine_configs (checkin_type, time_segment, fine_amount)
                VALUES ($1, $2, $3)
                ON CONFLICT (checkin_type, time_segment)
                DO UPDATE SET fine_amount = EXCLUDED.fine_amount
                """,
                checkin_type,
                time_segment,
                fine_amount,
            )

    async def clear_work_fine_rates(self, checkin_type: str):
        """æ¸…ç©ºä¸Šä¸‹ç­ç½šæ¬¾é…ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM work_fine_configs WHERE checkin_type = $1", checkin_type
            )

    # ========== æ¨é€è®¾ç½®æ“ä½œ ==========
    async def get_push_settings(self) -> Dict:
        """è·å–æ¨é€è®¾ç½®"""
        cache_key = "push_settings"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT * FROM push_settings")
            settings = {row["setting_key"]: bool(row["setting_value"]) for row in rows}
            self._set_cached(cache_key, settings, 300)
            return settings

    async def update_push_setting(self, key: str, value: bool):
        """æ›´æ–°æ¨é€è®¾ç½®"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO push_settings (setting_key, setting_value)
                VALUES ($1, $2)
                ON CONFLICT (setting_key) 
                DO UPDATE SET 
                    setting_value = EXCLUDED.setting_value,
                    created_at = CURRENT_TIMESTAMP
                """,
                key,
                1 if value else 0,
            )
        self._cache.pop("push_settings", None)

    # ========== ç»Ÿè®¡å’Œå¯¼å‡ºç›¸å…³ ==========
    async def get_group_statistics(
        self, chat_id: int, target_date: Optional[date] = None
    ) -> List[Dict]:
        """è·å–ç¾¤ç»„ç»Ÿè®¡ä¿¡æ¯"""
        if target_date is None:
            target_date = self.get_beijing_date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            users = await conn.fetch(
                """
                SELECT DISTINCT u.user_id, u.nickname, 
                    COALESCE(ua_total.total_accumulated_time, 0) as total_accumulated_time,
                    COALESCE(ua_total.total_activity_count, 0) as total_activity_count,
                    COALESCE(u.total_fines, 0) as total_fines,
                    COALESCE(u.overtime_count, 0) as overtime_count,
                    COALESCE(u.total_overtime_time, 0) as total_overtime_time
                FROM users u
                LEFT JOIN (
                    SELECT user_id, 
                        SUM(accumulated_time) as total_accumulated_time,
                        SUM(activity_count) as total_activity_count
                    FROM user_activities 
                    WHERE chat_id = $1 AND activity_date = $2
                    GROUP BY user_id
                ) ua_total ON u.user_id = ua_total.user_id
                WHERE u.chat_id = $1 
                AND EXISTS (
                    SELECT 1 FROM user_activities 
                    WHERE chat_id = $1 AND user_id = u.user_id AND activity_date = $2
                )
                """,
                chat_id,
                target_date,
            )

            result = []
            for user in users:
                user_data = dict(user)

                # è·å–æ´»åŠ¨è¯¦æƒ…
                activities = await conn.fetch(
                    """
                    SELECT activity_name, activity_count, accumulated_time
                    FROM user_activities
                    WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3
                    """,
                    chat_id,
                    user["user_id"],
                    target_date,
                )

                user_data["activities"] = {}
                for row in activities:
                    user_data["activities"][row["activity_name"]] = {
                        "count": row["activity_count"],
                        "time": row["accumulated_time"],
                    }

                result.append(user_data)

            return result

    async def get_all_groups(self) -> List[int]:
        """è·å–æ‰€æœ‰ç¾¤ç»„ID"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch("SELECT chat_id FROM groups")
            return [row["chat_id"] for row in rows]

    async def get_group_members(
        self, chat_id: int, target_datetime: datetime = None
    ) -> List[Dict]:
        """è·å–ç¾¤ç»„æˆå‘˜ - æ ¹æ®é‡ç½®å‘¨æœŸ"""
        if target_datetime is None:
            target_datetime = self.get_beijing_time()

        # ğŸ¯ è·å–å½“å‰é‡ç½®å‘¨æœŸæ—¥æœŸ
        period_date = await self.get_reset_period_date(chat_id, target_datetime)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT user_id, nickname, current_activity, activity_start_time, 
                    total_accumulated_time, total_activity_count, total_fines, 
                    overtime_count, total_overtime_time, last_updated 
                FROM users 
                WHERE chat_id = $1 AND last_updated = $2
                """,
                chat_id,
                period_date,  # ğŸ¯ ä½¿ç”¨é‡ç½®å‘¨æœŸæ—¥æœŸ
            )
            return [dict(row) for row in rows]

    # ========== æœˆåº¦ç»Ÿè®¡ ==========

    async def get_monthly_statistics(
        self, chat_id: int, year: int = None, month: int = None
    ) -> List[Dict]:
        """ä¿®å¤ç‰ˆï¼šè·å–æœˆåº¦ç»Ÿè®¡ - é‡‡ç”¨åˆ†ç±»é¢„èšåˆï¼Œå½»åº•è§£å†³é‡å¤è®¡ç®—ä¸æ€§èƒ½é—®é¢˜"""

        if year is None or month is None:
            # ç»Ÿä¸€ä½¿ç”¨ datetime ä»¥ç¡®ä¿æ—¶åŒºæ­£ç¡®
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        # è¯¥æœˆ 1 å·ä½œä¸ºç»Ÿè®¡å‘¨æœŸ
        statistic_date = date(year, month, 1)

        self._ensure_pool_initialized()

        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                WITH grouped_stats AS (
                    SELECT 
                        user_id,
                        activity_name,
                        SUM(activity_count) AS sum_count,
                        SUM(accumulated_time) AS sum_time
                    FROM monthly_statistics
                    WHERE chat_id = $1 AND statistic_date = $2
                    GROUP BY user_id, activity_name
                ),
                user_metrics AS (
                    SELECT 
                        user_id,
                        MAX(CASE WHEN activity_name = 'work_days' THEN sum_count ELSE 0 END) AS work_days,
                        MAX(CASE WHEN activity_name = 'work_hours' THEN sum_time ELSE 0 END) AS work_hours,
                        MAX(CASE WHEN activity_name = 'total_fines' THEN sum_time ELSE 0 END) AS total_fines,
                        MAX(CASE WHEN activity_name = 'overtime_count' THEN sum_count ELSE 0 END) AS overtime_count,
                        MAX(CASE WHEN activity_name = 'overtime_time' THEN sum_time ELSE 0 END) AS total_overtime_time,

                        SUM(CASE 
                            WHEN activity_name NOT IN (
                                'work_days','work_hours','total_fines',
                                'overtime_count','overtime_time'
                            ) THEN sum_count ELSE 0 END
                        ) AS total_activity_count,

                        SUM(CASE 
                            WHEN activity_name NOT IN (
                                'work_days','work_hours','total_fines',
                                'overtime_count','overtime_time'
                            ) THEN sum_time ELSE 0 END
                        ) AS total_accumulated_time
                    FROM grouped_stats
                    GROUP BY user_id
                ),
                activity_json AS (
                    SELECT
                        user_id,
                        jsonb_object_agg(
                            activity_name,
                            jsonb_build_object('count', sum_count, 'time', sum_time)
                        ) AS activities
                    FROM grouped_stats
                    WHERE activity_name NOT IN (
                        'work_days','work_hours','total_fines',
                        'overtime_count','overtime_time'
                    )
                    GROUP BY user_id
                )
                SELECT 
                    um.*,
                    u.nickname,
                    COALESCE(aj.activities, '{}'::jsonb) AS activities
                FROM user_metrics um
                LEFT JOIN users u 
                    ON u.chat_id = $1 AND u.user_id = um.user_id
                LEFT JOIN activity_json aj 
                    ON um.user_id = aj.user_id
                ORDER BY um.total_accumulated_time DESC
                """,
                chat_id,
                statistic_date,
            )

        result: List[Dict] = []
        for row in rows:
            data = dict(row)

            # ç¡®ä¿ activities æ°¸è¿œæ˜¯ dict
            if isinstance(data.get("activities"), str):
                import json

                data["activities"] = json.loads(data["activities"])
            elif data.get("activities") is None:
                data["activities"] = {}

            result.append(data)

        return result

    async def get_monthly_work_statistics(
        self, chat_id: int, year: int = None, month: int = None
    ) -> List[Dict]:
        """è·å–æœˆåº¦ä¸Šä¸‹ç­ç»Ÿè®¡"""
        if year is None or month is None:
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        start_date = date(year, month, 1)
        if month == 12:
            end_date = date(year + 1, 1, 1)
        else:
            end_date = date(year, month + 1, 1)

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT 
                    wr.user_id,
                    u.nickname,
                    COUNT(CASE WHEN wr.checkin_type = 'work_start' THEN 1 END) as work_start_count,
                    COUNT(CASE WHEN wr.checkin_type = 'work_end' THEN 1 END) as work_end_count,
                    SUM(CASE WHEN wr.checkin_type = 'work_start' THEN wr.fine_amount ELSE 0 END) as work_start_fines,
                    SUM(CASE WHEN wr.checkin_type = 'work_end' THEN wr.fine_amount ELSE 0 END) as work_end_fines
                FROM work_records wr
                JOIN users u ON wr.chat_id = u.chat_id AND wr.user_id = u.user_id
                WHERE wr.chat_id = $1 AND wr.record_date >= $2 AND wr.record_date < $3
                GROUP BY wr.user_id, u.nickname
                """,
                chat_id,
                start_date,
                end_date,
            )
            return [dict(row) for row in rows]

    async def get_monthly_activity_ranking(
        self, chat_id: int, year: int = None, month: int = None
    ) -> Dict[str, List]:
        """è·å–æœˆåº¦æ´»åŠ¨æ’è¡Œæ¦œ"""
        if year is None or month is None:
            today = self.get_beijing_time()
            year = today.year
            month = today.month

        statistic_date = date(year, month, 1)
        activity_limits = await self.get_activity_limits()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rankings = {}
            for activity in activity_limits.keys():
                rows = await conn.fetch(
                    """
                    SELECT 
                        ms.user_id,
                        u.nickname,
                        ms.accumulated_time as total_time,
                        ms.activity_count as total_count
                    FROM monthly_statistics ms
                    JOIN users u ON ms.chat_id = u.chat_id AND ms.user_id = u.user_id
                    WHERE ms.chat_id = $1 AND ms.activity_name = $2 
                        AND ms.statistic_date = $3
                    ORDER BY ms.accumulated_time DESC
                    LIMIT 10
                    """,
                    chat_id,
                    activity,
                    statistic_date,
                )
                rankings[activity] = [dict(row) for row in rows]
            return rankings

    async def get_user_late_early_counts(
        self, chat_id: int, user_id: int, year: int, month: int
    ) -> Dict[str, int]:
        """è·å–ç”¨æˆ·çš„è¿Ÿåˆ°æ—©é€€æ¬¡æ•°ç»Ÿè®¡"""
        start_date = date(year, month, 1)
        if month == 12:
            end_date = date(year + 1, 1, 1)
        else:
            end_date = date(year, month + 1, 1)

        async with self.pool.acquire() as conn:
            # è·å–è¿Ÿåˆ°æ¬¡æ•°ï¼ˆä¸Šç­æ—¶é—´å·®>0ï¼‰
            late_count = (
                await conn.fetchval(
                    """
                SELECT COUNT(*) FROM work_records 
                WHERE chat_id = $1 AND user_id = $2 
                AND record_date >= $3 AND record_date < $4
                AND checkin_type = 'work_start' AND time_diff_minutes > 0
                """,
                    chat_id,
                    user_id,
                    start_date,
                    end_date,
                )
                or 0
            )

            # è·å–æ—©é€€æ¬¡æ•°ï¼ˆä¸‹ç­æ—¶é—´å·®<0ï¼‰
            early_count = (
                await conn.fetchval(
                    """
                SELECT COUNT(*) FROM work_records 
                WHERE chat_id = $1 AND user_id = $2 
                AND record_date >= $3 AND record_date < $4
                AND checkin_type = 'work_end' AND time_diff_minutes < 0
                """,
                    chat_id,
                    user_id,
                    start_date,
                    end_date,
                )
                or 0
            )

            return {"late_count": late_count, "early_count": early_count}

    # ========== æ•°æ®æ¸…ç† ==========
    async def cleanup_old_data(self, days: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_date = (self.get_beijing_time() - timedelta(days=days)).date()

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            async with conn.transaction():
                await conn.execute(
                    "DELETE FROM user_activities WHERE activity_date < $1", cutoff_date
                )
                await conn.execute(
                    "DELETE FROM work_records WHERE record_date < $1", cutoff_date
                )
                await conn.execute(
                    "DELETE FROM users WHERE last_updated < $1", cutoff_date
                )

    async def cleanup_monthly_data(self, target_date: date = None):
        """æ¸…ç†æœˆåº¦ç»Ÿè®¡æ•°æ®"""
        if target_date is None:
            today = self.get_beijing_time()
            # ä½¿ç”¨é…ç½®è€Œä¸æ˜¯ç¡¬ç¼–ç 90å¤©
            monthly_cutoff = (
                (today - timedelta(days=Config.MONTHLY_DATA_RETENTION_DAYS))
                .date()
                .replace(day=1)
            )
            target_date = monthly_cutoff

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            result = await conn.execute(
                "DELETE FROM monthly_statistics WHERE statistic_date < $1", target_date
            )
            return (
                int(result.split()[-1]) if result and result.startswith("DELETE") else 0
            )

    async def cleanup_specific_month(self, year: int, month: int):
        """æ¸…ç†æŒ‡å®šå¹´æœˆçš„æœˆåº¦ç»Ÿè®¡æ•°æ®"""
        target_date = date(year, month, 1)
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            result = await conn.execute(
                "DELETE FROM monthly_statistics WHERE statistic_date = $1", target_date
            )
            return (
                int(result.split()[-1]) if result and result.startswith("DELETE") else 0
            )

    async def cleanup_inactive_users(self, days: int = 30):
        """æ¸…ç†é•¿æœŸæœªæ´»åŠ¨ç”¨æˆ·åŠå…¶è®°å½•ï¼ˆå®‰å…¨ç‰ˆï¼‰"""

        cutoff_date = (self.get_beijing_time() - timedelta(days=days)).date()

        async with self.pool.acquire() as conn:
            async with conn.transaction():

                # æ‰¾å‡ºè¦åˆ é™¤çš„ç”¨æˆ·åˆ—è¡¨ï¼ˆé¿å…ç›´æ¥åˆ ï¼‰
                users_to_delete = await conn.fetch(
                    """
                        SELECT user_id 
                        FROM users
                        WHERE last_updated < $1
                        AND NOT EXISTS (
                            SELECT 1 FROM monthly_statistics 
                            WHERE monthly_statistics.chat_id = users.chat_id 
                            AND monthly_statistics.user_id = users.user_id
                        )
                        """,
                    cutoff_date,
                )

                user_ids = [u["user_id"] for u in users_to_delete]

                if not user_ids:
                    logger.info("ğŸ§¹ æ— éœ€æ¸…ç†ç”¨æˆ·")
                    return 0

                # åˆ é™¤ç”¨æˆ·çš„æ—¥å¸¸è®°å½•
                await conn.execute(
                    "DELETE FROM user_activities WHERE user_id = ANY($1)",
                    user_ids,
                )

                # åˆ é™¤ä¸Šä¸‹ç­è®°å½•ï¼ˆå¦‚æœä½ éœ€è¦ï¼‰
                await conn.execute(
                    "DELETE FROM work_records WHERE user_id = ANY($1)",
                    user_ids,
                )

                # æœ€ååˆ é™¤ç”¨æˆ·
                deleted_count = await conn.execute(
                    "DELETE FROM users WHERE user_id = ANY($1)",
                    user_ids,
                )

        logger.info(f"ğŸ§¹ æ¸…ç†äº† {deleted_count} ä¸ªé•¿æœŸæœªæ´»åŠ¨çš„ç”¨æˆ·ä»¥åŠä»–ä»¬çš„æ‰€æœ‰è®°å½•")
        return deleted_count

    # ========== æ´»åŠ¨äººæ•°é™åˆ¶ ==========
    async def set_activity_user_limit(self, activity: str, max_users: int):
        """è®¾ç½®æ´»åŠ¨äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO activity_user_limits (activity_name, max_users)
                VALUES ($1, $2)
                ON CONFLICT (activity_name)
                DO UPDATE SET 
                    max_users = EXCLUDED.max_users,
                    updated_at = CURRENT_TIMESTAMP
                """,
                activity,
                max_users,
            )
        self._cache.pop(f"activity_limit:{activity}", None)

    async def get_activity_user_limit(self, activity: str) -> int:
        """è·å–æ´»åŠ¨äººæ•°é™åˆ¶"""
        cache_key = f"activity_limit:{activity}"
        cached = self._get_cached(cache_key)
        if cached is not None:
            return cached

        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            row = await conn.fetchrow(
                "SELECT max_users FROM activity_user_limits WHERE activity_name = $1",
                activity,
            )
            limit = row["max_users"] if row else 0
            self._set_cached(cache_key, limit, 60)
            return limit

    async def get_current_activity_users(self, chat_id: int, activity: str) -> int:
        """è·å–å½“å‰æ­£åœ¨è¿›è¡ŒæŒ‡å®šæ´»åŠ¨çš„ç”¨æˆ·æ•°é‡"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            count = await conn.fetchval(
                "SELECT COUNT(*) FROM users WHERE chat_id = $1 AND current_activity = $2",
                chat_id,
                activity,
            )
            return count or 0

    async def get_all_activity_limits(self) -> Dict[str, int]:
        """è·å–æ‰€æœ‰æ´»åŠ¨çš„äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            rows = await conn.fetch(
                "SELECT activity_name, max_users FROM activity_user_limits"
            )
            return {row["activity_name"]: row["max_users"] for row in rows}

    async def remove_activity_user_limit(self, activity: str):
        """ç§»é™¤æ´»åŠ¨äººæ•°é™åˆ¶"""
        self._ensure_pool_initialized()
        async with self.pool.acquire() as conn:
            await conn.execute(
                "DELETE FROM activity_user_limits WHERE activity_name = $1", activity
            )
        self._cache.pop(f"activity_limit:{activity}", None)

    # ========== å·¥å…·æ–¹æ³• ==========
    @staticmethod
    def format_time_for_csv(seconds: int) -> str:
        """ä¸ºCSVå¯¼å‡ºæ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if not seconds:
            return "0åˆ†0ç§’"

        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60

        if hours > 0:
            return f"{hours}æ—¶{minutes}åˆ†{secs}ç§’"
        else:
            return f"{minutes}åˆ†{secs}ç§’"

    async def connection_health_check(self) -> bool:
        """å¿«é€Ÿè¿æ¥å¥åº·æ£€æŸ¥"""
        if not self.pool:
            return False

        try:
            async with self.pool.acquire() as conn:
                result = await conn.fetchval("SELECT 1")
                return result == 1
        except Exception as e:
            logger.debug(f"æ•°æ®åº“è¿æ¥å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    # ========= éªŒè¯æ•°æ®å®Œæ•´æ€§ =========
    async def validate_system_integrity(self, chat_id: int):
        """éªŒè¯ç³»ç»Ÿæ•°æ®å®Œæ•´æ€§"""
        now = self.get_beijing_time()

        # 1ï¸âƒ£ éªŒè¯é‡ç½®å‘¨æœŸè®¡ç®—
        period_date = await self.get_reset_period_date(chat_id, now)
        logger.info(f"éªŒè¯ç¾¤ç»„ {chat_id} é‡ç½®å‘¨æœŸ: {period_date}")

        # 2ï¸âƒ£ éªŒè¯ç”¨æˆ·æ•°æ®ä¸€è‡´æ€§
        members = await self.get_group_members(chat_id, now)
        inconsistencies = []

        for member in members:
            uid = member["user_id"]

            # æ£€æŸ¥ users è¡¨å’Œ user_activities è¡¨çš„æ•°æ®æ˜¯å¦ä¸€è‡´
            user_data = await self.get_user_cached(chat_id, uid, now)

            if not user_data:
                logger.warning(f"ç”¨æˆ· {uid} æ•°æ®ä¸å­˜åœ¨")
                continue

            # ğŸ¯ ä½¿ç”¨ç›¸åŒçš„é‡ç½®å‘¨æœŸæ—¥æœŸæŸ¥è¯¢æ´»åŠ¨æ•°æ®
            activities = {}
            try:
                async with self.pool.acquire() as conn:
                    rows = await conn.fetch(
                        """
                        SELECT activity_name, activity_count, accumulated_time 
                        FROM user_activities 
                        WHERE chat_id = $1 AND user_id = $2 AND activity_date = $3
                        """,
                        chat_id,
                        uid,
                        period_date,
                    )
                    for row in rows:
                        activities[row["activity_name"]] = {
                            "count": row["activity_count"],
                            "time": row["accumulated_time"],
                        }
            except Exception as e:
                logger.error(f"æŸ¥è¯¢ç”¨æˆ· {uid} æ´»åŠ¨æ•°æ®å¤±è´¥: {e}")
                continue

            # è®¡ç®—æ€»æ¬¡æ•°
            total_from_activities = sum(
                info.get("count", 0) for info in activities.values()
            )

            user_total = user_data.get("total_activity_count", 0)

            if user_total != total_from_activities:
                inconsistency = {
                    "user_id": uid,
                    "nickname": user_data.get("nickname", "æœªçŸ¥"),
                    "users_table_count": user_total,
                    "activities_table_count": total_from_activities,
                    "difference": abs(user_total - total_from_activities),
                }
                inconsistencies.append(inconsistency)
                logger.warning(
                    f"æ•°æ®ä¸ä¸€è‡´: ç”¨æˆ·{uid}({inconsistency['nickname']}), "
                    f"usersè¡¨={user_total}, activitiesè¡¨={total_from_activities}"
                )

        # 3ï¸âƒ£ éªŒè¯æœˆåº¦ç»Ÿè®¡ä¸æ—¥å¸¸ç»Ÿè®¡çš„ä¸€è‡´æ€§
        monthly_inconsistencies = []
        if inconsistencies:
            # æ£€æŸ¥æœˆåº¦ç»Ÿè®¡æ˜¯å¦åŒ…å«è¿™äº›æ•°æ®
            today = now.date()
            statistic_date = today.replace(day=1)

            for inc in inconsistencies:
                uid = inc["user_id"]
                # æ£€æŸ¥æœˆåº¦ç»Ÿè®¡æ˜¯å¦æœ‰è¯¥ç”¨æˆ·çš„æ•°æ®
                async with self.pool.acquire() as conn:
                    monthly_exists = await conn.fetchval(
                        """
                        SELECT 1 FROM monthly_statistics 
                        WHERE chat_id = $1 AND user_id = $2 AND statistic_date = $3
                        LIMIT 1
                        """,
                        chat_id,
                        uid,
                        statistic_date,
                    )
                    if not monthly_exists:
                        monthly_inconsistencies.append(uid)
                        logger.warning(f"ç”¨æˆ· {uid} æœˆåº¦ç»Ÿè®¡ç¼ºå¤±")

        return {
            "period_date": period_date,
            "total_members": len(members),
            "inconsistent_users": len(inconsistencies),
            "inconsistencies": inconsistencies,
            "monthly_missing_users": len(monthly_inconsistencies),
            "monthly_missing_user_ids": monthly_inconsistencies,
            "timestamp": now.isoformat(),
        }


# å…¨å±€æ•°æ®åº“å®ä¾‹
db = PostgreSQLDatabase()
